AnimateAnywhere: Rouse the Background in Human Image Animation

人体图像动画生成旨在根据给定的人物角色和背景生成符合指定姿态序列的人类视频。然而，现有方法更多关注人物动作而忽视了背景的动态生成，这通常会导致静态结果或背景运动不协调的问题。学界虽已探索过相机位姿引导的动画生成任务，但为大多数娱乐应用和普通用户准备相机运动轨迹并不现实。为此，我们提出了AnimateAnywhere框架，无需依赖相机轨迹即可在人体动画中激发背景动态。基于"人体运动往往反映背景动态"这一关键发现，我们设计了背景运动学习器（BML），从人体姿态序列中学习背景运动规律。为了增强模型对跨帧对应关系的精确学习，我们进一步在三维注意力图上施加极线约束：通过将极线掩膜与当前三维注意力图相结合，精心构建出抑制几何不合理注意力的掩膜系统。大量实验证明，我们的AnimateAnywhere能有效从人体姿态序列中学习背景运动规律，在生成具有生动逼真背景的人类动画效果方面达到业界领先水平。源代码和模型将在<https://github.com/liuxiaoyu1104/AnimateAnywhere> 发布。
