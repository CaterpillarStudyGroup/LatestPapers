Dyadic Mamba: Long-term Dyadic Human Motion Synthesis

从文本描述生成逼真的双人交互人体运动面临重大挑战，尤其是在处理超出常规训练序列长度的长时交互场景时。尽管近期基于Transformer的方法在短时双人运动合成中展现出良好效果，但由于位置编码方案的内在限制，这些方法在生成长序列时表现欠佳。本文提出Dyadic Mamba，一种利用状态空间模型(SSMs)生成任意长度高质量双人人体运动的新方法。我们的方法采用简洁有效的架构设计，通过序列拼接实现个体运动序列间的信息流动，无需复杂的交叉注意力机制。实验表明，Dyadic Mamba在标准短时基准测试中取得了具有竞争力的性能，同时在长序列生成上显著优于基于Transformer的方法。此外，我们提出了评估长时运动合成质量的新基准测试，为未来研究提供标准化框架。研究结果表明，基于SSM的架构为解决文本驱动长时双人人体运动合成这一难题提供了新的研究方向。
