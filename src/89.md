Dyadic Mamba: Long-term Dyadic Human Motion Synthesis

从文本描述生成逼真的双人交互动作面临重大挑战，尤其是当交互时长超过典型训练序列长度时。尽管近期基于Transformer的方法在短期双人动作合成上展现出良好效果，但由于位置编码机制的内在限制，这些方法难以处理长序列生成。本文提出"Dyadic Mamba" —— 一种利用状态空间模型(SSMs)生成任意长度高质量双人动作的创新方法。我们的架构设计简洁高效，通过序列拼接实现个体动作间的信息流动，无需复杂的交叉注意力机制。实验表明，Dyadic Mamba不仅在标准短期动作基准测试中表现优异，更在长序列生成上显著超越基于Transformer的方法。此外，我们提出了评估长时动作合成质量的新基准，为未来研究建立标准化框架。研究结果证明，基于状态空间模型的架构为解决文本到长时双人动作合成这一难题提供了新的研究方向。

