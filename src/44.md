MVHumanNet++: A Large-scale Dataset of Multi-view Daily Dressing Human Captures with Richer Annotations for 3D Human Digitization 

在这个时代，大语言模型和文生图模型的成功得益于大规模数据集的驱动。然而在3D视觉领域，虽然通过Objaverse和MVImgNet等大规模数据集在以物体为中心的任务上取得了显著进展，但以人为中心的任务发展却相对受限，这主要源于缺乏可比拟的大规模人体数据集。为了填补这一空白，我们推出了MVHumanNet++数据集 —— 该数据集包含4500位人物身份的多视角人体动作序列。本项工作的核心在于通过多视角人体捕捉系统，采集具有大规模身份多样性和日常服饰特征的人类数据，这种采集方式具备高度的可扩展性。我们的数据集涵盖9000套日常服装、6万组动作序列和6.45亿帧画面，并提供丰富的标注信息，包括人体遮罩、相机参数、2D/3D关键点、SMPL/SMPLX参数及对应文本描述。此外，我们对MVHumanNet++数据集进行了增强处理，新增法线贴图和深度图标注，显著提升了其在先进人体中心研究中的适用性与实用价值。为了探索该数据集在2D/3D视觉任务中的潜力，我们开展了多项先导研究，充分展现了MVHumanNet++的规模优势所带来的性能提升与创新应用。作为当前最大规模的3D人体数据集，我们希望通过开放MVHumanNet++及其标注信息，推动大规模3D人体中心任务领域的创新发展。该数据集已通过<https://kevinlee09.github.io/research/MVHumanNet++/> 公开发布。

