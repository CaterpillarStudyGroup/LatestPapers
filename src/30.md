Common3D: Self-Supervised Learning of 3D Morphable Models for Common Objects in Neural Feature Space

三维可变形模型(3DMMs)是一种强大的工具，能够表示物体类别的潜在形状与外观。给定单张测试图像时，3DMMs可用于解决多种任务，例如预测物体的三维形状、姿态、语义对应关系及实例分割。然而，目前3DMMs仅适用于极少数特定关注的对象类别(如人脸或人体)，因为它们需要复杂的3D数据采集和针对特定类别的训练流程。相比之下，我们提出了一种新方法Common3D——通过从以物体为中心的视频集合中完全自监督的方式学习常见物体的3D可变形模型。

为实现这一目标，我们的模型将物体表征为一个学习得到的3D模板网格和一个以图像为条件的神经网络参数化的变形场。与先前工作不同，Common3D使用神经特征而非RGB颜色描述物体外观，这种对像素强度的抽象使学习到的表征具有更强的泛化性。值得注意的是，我们通过利用可变形模板网格定义的对应关系，采用对比目标训练外观特征。相较于相关研究，该方法产生了更高质量的对应特征，并显著提升了模型在估计三维物体姿态和语义对应任务中的性能。Common3D是首个完全自监督且能以零样本方式解决多种视觉任务的方法。