
EWMBench: Evaluating Scene, Motion, and Semantic Quality in Embodied World Models

近年来，创造性人工智能的突破使得基于语言指令合成高保真度图像与视频成为可能。在此基础之上，文生视频扩散模型已进化为具身世界模型(EWM)，能够根据语言命令生成物理合理的场景，在具身人工智能应用中有效实现了视觉与行动的联结。本研究针对超越通用感知指标评估具身世界模型这一关键挑战，旨在确保生成内容符合物理规律且与行动逻辑一致。我们提出具身世界模型基准测试(EWMBench)，该专用评估框架围绕三大核心维度构建：视觉场景一致性、运动正确性与语义对齐度。通过精心构建的多样化场景与运动模式数据集，结合多维度的综合评估工具包，我们的方法可系统测评候选模型性能。该基准测试不仅揭示了现有视频生成模型在满足具身任务特殊需求方面的局限性，更为该领域未来发展提供了重要指引。完整数据集与评估工具已开源：<https://github.com/AgibotTech/EWMBench>。

