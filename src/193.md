iDiT-HOI: Inpainting-based Hand Object Interaction Reenactment via Video Diffusion Transformer


**数字人视频生成**技术在教育、电子商务等领域正日益受到关注，这主要得益于头部-身体动画和唇形同步技术的进步。然而，实现逼真的**手物交互（Hand-Object Interaction, HOI）**——即人手与物体之间复杂的动态关系——仍然面临诸多挑战。生成自然可信的手物交互重演非常困难，原因包括：手与物体之间的遮挡问题、物体形状和朝向的多样性、对精确物理交互的需求，以及**关键的是**，模型需要具备泛化到**未见过的**人和物体的能力。    

本文提出了一种新颖的框架 **iDiT-HOI**，它能够实现**野外环境下的手物交互重演生成**。具体来说，我们提出了一种统一的、基于修复的令牌处理方法 **Inp-TPU**，该方法结合了一个**两阶段视频扩散Transformer（DiT）模型**。第一阶段通过将指定物体插入手部区域来生成关键帧，为后续帧提供参考。第二阶段则确保手物交互的时间连贯性和流畅性。    

我们方法的核心贡献在于：**无需引入额外参数**，即可**重用预训练模型的上下文感知能力**，从而实现对未见物体和场景的强大泛化能力；同时，我们提出的范式**天然支持生成长视频**。全面的评估表明，我们的方法优于现有技术，尤其是在具有挑战性的真实世界场景中，提供了更强的真实感和更无缝的手物交互效果。    