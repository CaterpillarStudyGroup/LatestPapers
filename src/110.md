Intentional Gesture: Deliver Your Intentions with Gestures for Speech

当人类说话时，手势有助于传达交流意图，例如增强重点或描述概念。然而，当前的伴随语音手势生成方法仅依赖于表层语言线索(如语音音频或文本转录)，忽视了对支撑人类手势的交流意图的理解与利用。这导致生成的肢体动作虽然能与语音节奏同步，但在语义层面却流于肤浅。为弥补这一不足，我们提出**意图驱动手势生成框架(Intentional-Gesture)** —— 通过将手势生成构建为基于高层交流功能的意图推理任务，开创性地实现深度语义表达。

% 首先，我们通过为BEAT-2数据集添加手势意图标注(即总结意图的文本语句)构建了**InG**数据集，这些标注由大规模视觉语言模型自动生成。接着，我们开发了**意图手势动作分词器**来利用这些意图标注。该组件将高层交流功能(如意图)注入分词化的动作表征中，实现兼具时序对齐和语义深度的意图感知手势合成，在BEAT-2基准测试中达到新的最优性能。本框架为数字人类与具身AI的富有表现力的手势生成提供了模块化基础架构。项目页面：<https://andypinxinliu.github.io/Intentional-Gesture>  

