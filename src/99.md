MonoMobility: Zero-Shot 3D Mobility Analysis from Monocular Videos

准确分析动态环境中的运动部件及其运动属性对于推动具身智能等关键领域的发展至关重要。针对现有方法依赖密集多视角图像或详细部件级标注的局限性，我们提出了一种创新框架，能够以零样本方式从单目视频中分析三维运动特性。该框架仅需单目视频即可精确解析运动部件及其运动属性，完全无需任何标注训练数据。具体而言，我们的方法首先通过深度估计、光流分析和点云配准技术构建场景几何结构并初步分析运动部件及其初始运动属性，继而采用二维高斯泼溅进行场景表征。在此基础上，我们针对铰接式物体专门设计了一种端到端动态场景优化算法，通过迭代优化逐步细化初始分析结果，从而确保系统能够处理"旋转"、"平移"乃至复杂运动("旋转+平移")，展现出高度的灵活性和普适性。为验证方法的鲁棒性和广泛适用性，我们构建了包含仿真场景和真实场景的综合性数据集。实验结果表明，该框架能够在无标注条件下有效解析铰接物体运动，展现了其在未来具身智能应用中的重要潜力。

