Multi-Person Interaction Generation from Two-Person Motion Priors


利用高层级控制生成逼真人体运动，对于社会行为理解、机器人技术和动画制作至关重要。随着高质量动作捕捉(MOCAP)数据的日益普及，各类数据驱动方法相继被提出。然而，多人交互运动建模领域的研究仍相对匮乏。本文提出图驱动交互采样法(Graph-driven Interaction Sampling)，该方法能够利用现有双人运动扩散模型作为运动先验，生成逼真且多样化的多人交互动作。我们的核心思路是：无需专门训练多人交互合成模型，而是将复杂的多人交互在时空维度分解为双人交互的图结构(称为成对交互图 Pairwise Interaction Graph)。由此将生成任务解耦为同步进行的、以他人动作为条件的单人运动生成。此外，为减少生成结果中的身体部位互穿等伪影，我们在扩散采样方案中引入了两项图相关引导机制。与现有方法不同，本方案能在避免个体动作重复的前提下，生成多样化的高质量多人交互。大量实验证明，在生成各类双人及多人交互时，本方法在减少伪影方面持续优于现有方案。   