ReAlign: Bilingual Text-to-Motion Generation via Step-Aware Reward-Guided Alignment

双语文本到运动生成通过双语文本输入合成3D人体运动，在游戏、影视和机器人等跨语言应用领域具有巨大潜力。然而，该任务面临两大关键挑战：缺乏双语运动-语言数据集，以及扩散模型中文本与运动分布的不对齐问题，导致生成运动存在语义不一致或质量低下的情况。为应对这些挑战，我们提出了BiHumanML3D双语人体运动数据集，为双语文本到运动生成模型建立了重要基准。此外，我们开发了双语运动扩散模型(BiMD)，通过跨语言对齐表征捕捉语义信息，实现统一的双语建模。在此基础上，我们提出了奖励引导的采样对齐方法(ReAlign)，包含用于评估采样过程中对齐质量的步态感知奖励模型，以及引导扩散过程向最优对齐分布演进的奖励引导策略。该奖励模型融合步态感知标记，结合保证语义一致性的文本对齐模块和提升真实性的运动对齐模块，通过在每一步优化噪声运动，平衡概率密度与对齐效果。实验表明，相较于现有最优方法，我们的方法在文本-运动对齐质量和运动生成质量上均有显著提升。项目主页：<https://wengwanjiang.github.io/ReAlign-page/>。