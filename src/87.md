HGM³: Hierarchical Generative Masked Motion Modeling with Hard Token Mining

文本驱动动作生成在动画、机器人技术以及增强现实/虚拟现实(AR/VR)等领域具有广泛的应用潜力。尽管当前基于掩码动作模型的研究取得了一定进展，但由于文本固有的模糊性及人体运动动力学的复杂性，该任务仍面临重大挑战。为突破这些限制，我们提出了一种创新的文本驱动动作生成框架，其核心包含两大关键技术：硬标记挖掘(HTM)和分层生成式掩码动作模型(HGM³)。通过HTM机制，系统可自动识别并遮蔽动作序列中的困难区域，引导模型集中学习难以掌握的动态特征；同时，分层模型采用语义图对文本进行多粒度表征，使模型能够学习上下文关联的合理动作。借助共享权重的掩码动作模型，该架构可在不同条件层级下重建相同序列，促进对复杂动作模式的全面学习。在推理阶段，模型通过由粗到细的渐进式生成策略逐步构建动作细节。在HumanML3D和KIT-ML等基准数据集上的大量实验表明，本方法在生成上下文感知动作的质量评价指标上均优于现有方法，展现出显著的性能优势。
