Locality Sensitive Avatars From Video

我们提出局部敏感化身(Locality-Sensitive Avatar)，这是一种基于神经辐射场(NeRF)的网络，用于从单目视频中学习人体运动。为此，我们通过从观测空间到规范空间的非线性映射，估计视频不同帧之间的规范表示，并将其分解为骨骼刚性运动和非刚性对应部分。我们的核心贡献在于：通过图神经网络(GNN)对非刚性部分进行建模，将姿态信息约束在相邻身体部位的局部范围内，从而保留细粒度细节。与先前仅在整个形状坐标空间操作的规范表示方法相比，我们的局部敏感运动建模能够同时还原逼真的形状轮廓与生动的细节。我们在ZJU-MoCap、SynWild、ActorsHQ、MVHumanNet及多种户外视频数据集上进行评估。实验表明，通过对规范特征空间进行局部敏感形变建模，我们首次实现了在新视角合成、新姿势动画和三维形状重建任务中均达到最先进水平。代码已开源：<https://github.com/ChunjinSong/lsavatar>。

