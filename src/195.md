PF-LHM: 3D Animatable Avatar Reconstruction from Pose-free Articulated Human Images


**从随手拍摄的图像重建可驱动的3D人体**    

从未经标定的相机或未提供人体姿态信息的随手拍摄图像中，重建一个关节化主体的可驱动3D人体模型，是一项实用但极具挑战性的任务。这主要源于视角偏差、遮挡以及缺乏结构先验知识等问题。尽管基于优化的方法能够从单目或多视角视频中生成高保真度的结果，但它们需要精确的姿态估计和缓慢的迭代优化过程，这限制了其在无约束场景下的可扩展性。近期的前馈式方法能够实现高效的单图像重建，但在有效利用多张输入图像以减少歧义并提升重建精度方面存在困难。    

为了应对这些挑战，我们提出了 **PF-LHM**，一个大型人体重建模型。它能够在一秒内从一张或多张随手拍摄的、无姿态信息的图像中生成高质量的3D虚拟化身。我们的方法引入了一种高效的**编码器-解码器点-图像Transformer架构**。该架构通过多模态注意力机制，融合了分层的几何点特征和多视角图像特征。融合后的特征被解码以恢复细节几何和外观，并采用3D高斯泼溅（3D Gaussian splats）技术进行表示。    

在真实和合成数据集上进行的大量实验表明，我们的方法统一了单图和多图3D人体重建，能够在无需相机和人体姿态标注的情况下，生成高保真度且可驱动的3D人体虚拟化身。代码和模型将向公众开源。    
