PhysiInter: Integrating Physical Mapping for High-Fidelity Human Interaction Generation


在动作捕捉技术和生成式人工智能进步的推动下，利用大规模动作捕捉数据集训练生成模型以合成多样化、逼真的人体运动，已成为一个前景广阔的研究方向。然而，现有的动作捕捉技术和生成模型常常忽略物理约束，导致诸如**穿透**、**滑动**和**悬空**等伪影。这些问题在涉及复杂交互的多人运动生成中尤为突出。    

为了克服这些局限，我们在整个人际交互生成流程中引入了**物理映射**。具体而言，通过在基于物理的模拟环境中进行**运动模仿**，将目标运动投影到一个物理上有效的空间。由此产生的运动经过调整，既遵循现实世界的物理约束，又保留了其原有的语义含义。这种映射不仅提高了动作捕捉数据的质量，还能直接指导生成运动的后处理。   

鉴于多人场景独特的交互性，我们提出了一个量身定制的**运动表示框架**。我们引入了**运动一致性损失 (Motion Consistency Loss, MC)** 和**基于标记的交互损失 (Marker-based Interaction Loss, MI)** 来提升模型性能。实验表明，我们的方法在生成人体运动质量方面取得了令人印象深刻的结果，**物理保真度提升了 3%-89%**。   

项目页面：<http://yw0208.github.io/physiinter>    