EVA: Expressive Virtual Avatars from Multi-view Videos

随着神经渲染和动作捕捉算法的快速发展，逼真人体化身建模技术取得了显著突破，在虚拟现实、增强现实、远程通信以及游戏、影视、医疗等行业释放出巨大潜力。然而，现有方法由于采用面部表情与肢体动作的纠缠式表征，无法实现对虚拟化身的完整、忠实且富有表现力的控制。本研究提出了富有表现力的虚拟化身(Expressive Virtual Avatars，EVA) —— 一种演员专用、完全可控且表现力丰富的数字人框架，该系统在实现高保真实时渲染的同时，能够对表情、肢体动作和手势进行独立控制。具体而言，我们创新性地将人体化身建模为双层架构：表现力模板几何层与三维高斯外观层。首先，我们开发了一种表现力模板追踪算法，通过由粗到精的优化策略，从多视角视频中精准重建肢体运动、面部表情及非刚性形变参数。其次，我们提出了一种新颖的解耦式三维高斯外观模型，旨在有效分离躯体与面部的视觉表征。与传统的统一高斯估计方法不同，本方法采用两个专门化独立模块分别建模躯体和面部。实验结果表明，EVA在渲染质量与表现力方面均超越现有最优方法，验证了其在构建全身虚拟化身方面的有效性。该研究标志着向全驱动数字人模型迈出了重要一步，为创建逼真再现人体几何特征与外观特征的数字分身提供了技术支撑。   