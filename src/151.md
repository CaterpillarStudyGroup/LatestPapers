SViMo: Synchronized Diffusion for Video and Motion Generation in Hand-object Interaction Scenarios


**人-物交互（HOI）生成**具有显著的应用潜力。然而，当前的三维HOI运动生成方法严重依赖于预定义的三维物体模型和实验室捕获的运动数据，这限制了其泛化能力。同时，HOI视频生成方法优先考虑像素级的视觉保真度，常常牺牲了物理合理性。    

我们认识到，在现实世界中，视觉外观和运动模式遵循着相同的基本物理定律。因此，我们提出了一种新颖的框架，该框架将**视觉先验**和**动态约束**结合在一个**同步扩散过程**中，以同时生成HOI视频和运动数据。   

为了整合异构的语义、外观和运动特征，我们的方法实现了**三模态自适应调制**以进行特征对齐，并结合**三维全注意力机制**来建模模态间和模态内的依赖关系。   

此外，我们引入了一个**视觉感知的三维交互扩散模型**。该模型直接从同步扩散的输出中生成**显式的三维交互序列**，然后将其反馈回去，形成一个**闭环反馈机制**。这种架构消除了对预定义物体模型或显式姿态指导的依赖，同时显著增强了**视频-运动一致性**。   

实验结果表明，我们的方法在生成高保真度、动态合理的HOI序列方面优于最先进的方法，并在未见过的真实世界场景中展现出卓越的泛化能力。项目页面位于：<\href{https://github.com/Droliven}{https://github.com/Droliven}>。   