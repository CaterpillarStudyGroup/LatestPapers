Follow-Your-Motion: Video Motion Transfer via Efficient Spatial-Temporal Decoupled Finetuning

近期，视频扩散变换器(video diffusion transformer)领域的突破性进展在多样化运动生成方面展现出卓越能力。在运动迁移任务上，当前方法主要采用两阶段低秩适配(Low-Rank Adaptations, LoRAs)微调来获得更好的性能。然而，现有的基于适配的运动迁移方法在应用于大型视频扩散变换器时，仍面临运动不一致性和调优效率低下的问题。由于3D注意力算子固有的时空耦合特性，简单的两阶段LoRA调优难以维持生成视频与输入视频之间的运动一致性。此外，它们需要在两个阶段都进行耗时的微调过程。

为了解决这些问题，我们提出了**Follow-Your-Motion**，一种高效的两阶段视频运动迁移框架，它通过微调强大的视频扩散变换器来合成复杂运动。具体而言：
1.  **时空解耦LoRA：** 我们提出了一种时空解耦的低秩适配器(LoRA)，将注意力架构解耦，分别用于处理空间外观和时间运动。
2.  **加速调优：** 在第二阶段训练期间，我们设计了**稀疏运动采样**和**自适应RoPE**(Rotary Position Embedding)技术来加速调优速度。

针对该领域缺乏基准测试的问题，我们引入了**MotionBench**，这是一个包含多样化运动的综合性基准测试集，涵盖创意摄像机运动、单物体运动、多物体运动以及复杂人体运动。我们在MotionBench上进行了广泛的评估，验证了Follow-Your-Motion的优越性。   