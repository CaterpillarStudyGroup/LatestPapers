SmallGS: Gaussian Splatting-based Camera Pose Estimation for Small-Baseline Videos

小基线运动的动态视频在日常生活中无处不在，尤其是在社交媒体上。然而，由于特征模糊、漂移累积以及三角测量约束不足，这些视频对现有的姿态估计框架提出了挑战。高斯泼溅(Gaussian splatting)通过对场景保持显式表示，在视角变化较小时能够提供可靠的新视图栅格化。受此启发，我们提出了SmallGS，这是一个专为小基线视频设计的相机姿态估计框架。该方法利用高斯泼溅优化序列相机位姿：首先在每个视频片段的首帧重建场景，为后续帧提供稳定参考。高斯泼溅在有限视角差异下的时间一致性特性，降低了传统相机姿态估计对深度剧烈变化的依赖。我们进一步将预训练的鲁棒视觉特征(如DINOv2)融入高斯泼溅，通过高维特征图渲染增强相机姿态估计的鲁棒性。通过冻结高斯泼溅模型并基于栅格化特征优化相机视角，SmallGS无需显式特征对应或强视差运动即可有效学习相机位姿。我们在TUM-Dynamics序列的小基线视频中验证了该方法的有效性：相较于MonST3R和DORID-SLAM，SmallGS在动态场景的小基线视频中实现了更精确的相机姿态估计。项目主页详见：<https://yuxinyao620.github.io/SmallGS>

