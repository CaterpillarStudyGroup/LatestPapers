|ID|Year|Name|Note|Tags|Link|
|---|---|---|---|---|---|
||2025.6.4|****||    |[link](1**.md)|
||2025.6.4|****||    |[link](1**.md)|
||2025.6.4|****||    |[link](1**.md)|
||2025.6.4|****||    |[link](1**.md)|
||2025.6.4|****||    |[link](1**.md)|

||2025.6.4|****||    |[link](1**.md)|
||2025.6.4|****||    |[link](1**.md)|
||2025.6.4|****||    |[link](1**.md)|
||2025.6.4|****||    |[link](1**.md)|
||2025.6.4|****||    |[link](1**.md)|

||2025.6.4|****||    |[link](1**.md)|
||2025.6.4|****||    |[link](1**.md)|
||2025.6.4|****||    |[link](1**.md)|
||2025.6.4|****||    |[link](1**.md)|
||2025.6.4|****||    |[link](1**.md)|

||2025.6.4|****||    |[link](1**.md)|
||2025.6.4|****||    |[link](1**.md)|
||2025.6.4|****||    |[link](1**.md)|
||2025.6.4|****||    |[link](1**.md)|
||2025.6.4|****||    |[link](1**.md)|

||2025.6.4|****||    |[link](1**.md)|
||2025.6.4|****||    |[link](1**.md)|
||2025.6.4|****||    |[link](1**.md)|
||2025.6.4|****||    |[link](1**.md)|
||2025.6.4|****||    |[link](1**.md)|

||2025.6.4|**EnliveningGS: Active Locomotion of 3DGS**|| 3D 高斯溅射(3DGS)表示的 3D 模型能够实现主动运动   |[link](154.md)|
||2025.6.3|Controllable Human-centric Keyframe Interpolation with Generative Prior||  3D关键帧插值器  |[link](152.md)|
||2025.6.3|SViMo: Synchronized Diffusion for Video and Motion Generation in Hand-object Interaction Scenarios|| 将**视觉先验**和**动态约束**结合在一个**同步扩散过程**中，以同时生成HOI视频和运动数据   |[link](151.md)|
||2025.6.2|HOSIG: Full-Body Human-Object-Scene Interaction Generation with Hierarchical Scene Perception|| 通过**分层场景感知**合成全身交互   |[link](150.md)|
||2025.6.2|UMA: Ultra-detailed Human Avatars via Multi-level Surface Alignment||  基于多视角视频学习具有生动动态效果与照片级真实感的可动画着装人体模型  |[link](148.md)|
||2025.5.30|DreamDance: Animating Character Art via Inpainting Stable Gaussian Worlds||  基于精确的相机轨迹生成稳定、一致的角色与场景运动  |[link](143.md)|
||2025.5.29|Generating Fit Check Videos with a Handheld Camera|| 仅需手持移动设备即可实现全身视频捕捉   |[link](141.md)|
||2025.5.29|Hallo4: High-Fidelity Dynamic Portrait Animation via Direct Preference Optimization and Temporal Motion Modulation||  由音频和骨骼运动驱动的高度动态且具有照片级真实感的肖像动画  |[link](137.md)|
||2025.5.29|HyperMotion: DiT-Based Pose-Guided Human Image Animation of Complex Motions| 高质量的人体姿态标注和精选的视频片段 |  数据集  |[link](136.md)|
||2025.5.27|Diffusion Model-based Activity Completion for AI Motion Capture from Videos|| 将AI动作捕捉应用于**虚拟人**领域   |[link](133.md)|
||2025.5.26|AniCrafter: Customizing Realistic Human-Centric Animation via Avatar-Background Conditioning in Video Diffusion Models||   将给定角色集成并动画化到开放域的动态背景中，同时遵循给定的人体运动序列 |[link](129.md)|
||2025.5.26|ParticleGS: Particle-Based Dynamics Modeling of 3D Gaussians for Prior-free Motion Extrapolation||  根据视觉观测数据建模三维高斯分布的动力学特性  |[link](128.md)|
||2025.5.26|DIPO: Dual-State Images Controlled Articulated Object Generation Powered by Diverse Data||  从一对图像可控生成铰接式三维物体  |[link](126.md)|
||2025.5.24|Flow Matching for Geometric Trajectory Simulation|| **通过融合流匹配技术和数据依赖耦合机制实现了基于物理知识的几何轨迹模拟**   |[link](122.md)|
||2025.5.23|How Much Do Large Language Models Know about Human Motion? A Case Study in 3D Avatar Control|| 大语言模型文生动作评估   |[link](131.md)|
||2025.5.23|CGS-GAN: 3D Consistent Gaussian Splatting GANs for High Resolution Human Head Synthesis||一种新颖的3D高斯泼溅GAN框架。它能够在无需依赖视角条件控制的情况下，实现稳定的训练和高质量、3D一致的人头像合成    |[link](120.md)|
||2025.5.23|DanceTogether! Identity-Preserving Multi-Person Interactive Video Generation||  将**单张参考图像**加上**独立的姿态掩膜流**转化为**长时、逼真的视频**，同时**严格保持每个角色的身份特征**  |[link](118.md)|
||2025.5.23|WonderPlay: Dynamic 3D Scene Generation from a Single Image and Actions|| 将物理模拟与视频生成技术相结合，能够基于单张图像生成动作条件化的动态三维场景   |[link](116.md)|
||2025.5.22|Motion Matters: Compact Gaussian Streaming for Free-Viewpoint Video Reconstruction|| 利用动态场景中运动的**局部性**和**一致性**，通过**关键点驱动的运动表示**来建模具有**物体一致性的高斯点运动**。通过仅传输关键点属性，该框架提供了一种更节省存储空间的解决方案。   |[link](115.md)|
||2025.5.22|Pursuing Temporal-Consistent Video Virtual Try-On via Dynamic Pose Interaction||  利用扩散模型深入研究视频虚拟试穿中的动态姿态交互  |[link](114.md)|
||2025.5.22|SHaDe: Compact and Consistent Dynamic 3D Reconstruction via Tri-Plane Deformation and Latent Diffusion||  一种新颖的动态3D场景重建框架  |[link](113.md)|
||2025.5.22|MAGIC: Motion-Aware Generative Inference via Confidence-Guided LLM|| **免训练**的、用于**单图像物理属性推断**与**动态生成**的框架   |[link](111.md)|
||2025.5.21|AsynFusion: Towards Asynchronous Latent Consistency Models for Decoupled Whole-Body Audio-Driven Avatars|| 全身音频驱动虚拟形象姿势与表情生成  |[link](109.md)|
||2025.5.21|GS2E: Gaussian Splatting is an Effective Data Generator for Event Stream Generation|| 真实世界稀疏多视角RGB图像重建的数据集  |[link](108.md)|
||2025.5.21|EVA: Expressive Virtual Avatars from Multi-view Videos|| 一种演员专用、完全可控且表现力丰富的数字人框架，该系统在实现高保真实时渲染的同时，能够对表情、肢体动作和手势进行独立控制  |[link](107.md)|
||2025.5.20|Hunyuan-Game: Industrial-grade Intelligent Game Creation Model|| 专为游戏场景定制的图像生成模型和视频生成模型  |[link](104.md)|
||2025.5.20|MGStream: Motion-aware 3D Gaussian for Streamable Dynamic Scene Reconstruction|| 3DGS可流式传输的动态新视角合成(DNVS)  |[link](102.md)|
||2025.5.19|RoPECraft: Training-Free Motion Transfer with Trajectory-Guided RoPE Optimization on Diffusion Transformers|| 一种面向扩散变换器的免训练视频运动迁移方法  |[link](98.md)|
||2025.5.18|Video-GPT via Next Clip Diffusion|| 将视频视为描述视觉世界的新型"语言"  |[link](100.md)|
||2025.5.17|MonoMobility: Zero-Shot 3D Mobility Analysis from Monocular Videos||  以零样本方式从单目视频中分析三维运动特性 |[link](99.md)|
||2025.5.16|Infinigen-Sim: Procedural Generation of Articulated Simulation Assets|| Blender工具，可创建铰链资源  |[link](93.md)|
||2025.5.16|PoseBench3D: A Cross-Dataset Analysis Framework for 3D Human Pose Estimation|| HPE的标准化测试环境  |[link](95.md)|
||2025.5.16|Locality Sensitive Avatars From Video|| 基于Nerf的HPE  |[link](90.md)|
||2025.5.15|**MTVCrafter: 4D Motion Tokenization for Open-World Human Image Animation**||  直接建模原始三维运动序列(即4D运动)的人体图像动画框架 |[link](86.md)|
||2025.5.14|SplineGS: Learning Smooth Trajectories in Gaussian Splatting for Dynamic Scene Reconstruction|| 3DGS复杂场景重建 |[link](79.md)|
||2025.5.13|**M3G: Multi-Granular Gesture Generator for Audio-Driven Full-Body Human Motion Synthesis**|| 个性化姿态的建模 |[link](80.md)|
||2025.5.12|**ShotAdapter: Text-to-Multi-Shot Video Generation with Diffusion Models**|| 文本到多镜头视频生成 |[link](73.md)|
||2025.5.12|**Human Motion Prediction via Test-domain-aware Adaptation with Easily-available Human Motions Estimated from Videos**||三维人体运动预测  |[link](72.md)|
||2025.5.9|MAGE:A Multi-stage Avatar Generator with Sparse Observations|| 从头戴式设备推断全身姿态 |[link](71.md)|
||2025.5.9|DiffLocks: Generating 3D Hair from a Single Image using Diffusion Models|| 单张图像重建3D头发 |[link](70.md)|
||2025.5.9|TeGA: Texture Space Gaussian Avatars for High-Resolution Dynamic Head Modeling|| 基于3DGS和稀疏体积（3D头部）重建与渲染 |[link](69.md)|
||2025.5.9|Anymate: A Dataset and Baselines for Learning 3D Object Rigging|| 蒙皮绑定数据集 |[link](68.md)|
||2025.5.8|SVAD: From Single Image to 3D Avatar via Synthetic Data Generation with Video Diffusion and Data Augmentation|| 从单张图像创建高质量可驱动的3D人体 |[link](61.md)|
||2025.5.7|PARC: Physics-based Augmentation with Reinforcement Learning for Character Controllers|| 基于物理模拟增强与强化学习的角色控制框架，过机器学习与物理仿真技术迭代增强运动数据集，持续拓展地形穿越控制器的能力。  |[link](55.md)|
||2025.5.7|PrimitiveAnything: Human-Crafted 3D Primitive Assembly Generation with Auto-Regressive Transformer||  形状基元抽象重新定义为基元装配生成任务 |[link](53.md)|
||2025.5.7|Bridging Geometry-Coherent Text-to-3D Generation with Multi-View Diffusion Priors and Gaussian Splatting|| SDS + 多视频耦合 -> CDS  |[link](52.md)|
||2025.5.6|Polar Coordinate-Based 2D Pose Prior with Neural Distance Field|| 动捕  |[link](49.md)|
||2025.5.6|GUAVA: Generalizable Upper Body 3D Gaussian Avatar||人体模型、上半身高斯重建   |[link](47.md)|
||2025.5.4|SignSplat: Rendering Sign Language via Gaussian Splatting|| 3DGS，细微动作重建 |[link](45.md)|
||2025.5.3|MVHumanNet++: A Large-scale Dataset of Multi-view Daily Dressing Human Captures with Richer Annotations for 3D Human Digitization || 数据集，多视角人体动作序列 |[link](44.md)|
||2025.5.2|3D Human Pose Estimation via Spatial Graph Order Attention and Temporal Body Aware Transformer|| 动捕 |[link](40.md)|
||2025.5.1|Direct Motion Models for Assessing Generated Videos|| 视频生成评价指标，物体交互，运动质量 |[link](33.md)|
||2025.5.1|Real-Time Animatable 2DGS-Avatars with Detail Enhancement from Monocular Videos|| 2DGS,SMPL,人体重建 |[link](32.md)|
||2025.4.30|CoCoDiff: Diversifying Skeleton Action Features via Coarse-Fine Text-Co-Guided Latent Diffusion|| 3D动作的特征多样性 |[link](31.md)|
||2025.4.30|Common3D: Self-Supervised Learning of 3D Morphable Models for Common Objects in Neural Feature Space|| 3DMM泛化到常见物体 |[link](30.md)|
||2025.4.30|HoloTime: Taming Video Diffusion Models for Panoramic 4D Scene Generation|| 4D场景生成 |[link](29.md)|
||2025.4.30|MagicPortrait: Temporally Consistent Face Reenactment with 3D Geometric Guidance|| 视频人脸驱动，FLAME |[link](28.md)|
||2025.4.29|Efficient Listener: Dyadic Facial Motion Synthesis via Action Diffusion|| Human Head Generation|[link](25.md)|
||2025.4.29|Creating Your Editable 3D Photorealistic Avatar with Tetrahedron-constrained Gaussian Splatting ||生成可编辑3D数字人|[link](24.md)|
||2025.4.29|SoccerDiffusion: Toward Learning End-to-End Humanoid Robot Soccer from Gameplay Recordings||踢足球仿真|[link](23.md)|
||2025.4.29|EfficientHuman: Efficient Training and Reconstruction of Moving Human using Articulated 2D Gaussian|| 2DGS重建运动人体|[link](21.md)|
||2025.4.28|Joint Optimization of Neural Radiance Fields and Continuous Camera Motion from a Monocular Video||重建与相机运行联合优化 |[link](20.md)|
||2025.4.28|HumMorph: Generalized Dynamic Human Neural Fields from Few Views|| 动态人体自由视角渲染|[link](18.md)|
||2025.4.27|Sketch2Anim: Towards Transferring Sketch Storyboards into 3D Animation||  |[link](76.md)|
||2025.4.27|Sketch2Anim: Towards Transferring Sketch Storyboards into 3D Animation|| 二维故事板草图转化为三维动画|[link](19.md)|
||2025.4.27|Generative AI for Character Animation: A Comprehensive Survey of Techniques, Applications, and Future Directions|| **角色动画综述**|[link](16.md)|
||2025.4.25|SSD-Poser: Avatar Pose Estimation with State Space Duality from Sparse Observations|| 疏观测实现稳健的全身运动估计|[link](11.md)|
||2025.4.25|STP4D: Spatio-Temporal-Prompt Consistent Modeling for Text-to-4D Gaussian Splatting|| **文本到4D生成**|[link](13.md)|
||2025.4.25|ActionArt: Advancing Multimodal Large Models for Fine-Grained Human-Centric Video Understanding|| 以人为中心的视频数据集|[link](15.md)|
||2025.4.24|3DV-TON: Textured 3D-Guided Consistent Video Try-on via Diffusion Models||虚拟试衣|[link](1.md)|
||2025.4.24|PICO: Reconstructing 3D People In Contact with Objects||人物交互3D重建|[link](4.md)|
||2025.4.23|PIN-WM: Learning Physics-INformed World Models for Non-Prehensile Manipulation|| 从视频数据中提取物理信息|[link](10.md)|
||2025.4.3|TokenHSI: Unified Synthesis of Physical Human-Scene Interactions through Task Tokenization|| 人-场景交互(HSI)  |[link](57.md)|
||2025|Draganything: Motion control for anything using entity representation|
||2023|Synthesizing Diverse Human Motions in 3D Indoor Scenes||  三维室内场景人物互动 |[link](64.md)|
||2022|Humanise: Language-conditioned human motion generation in 3d scenes ||  人-场景交互（HSI）数据集 |[link](65.md)|

# 删除


# Low

|ID|Year|Name|Note|Tags|Link|
|---|---|---|---|---|---|
||2025.6.3|LinkTo-Anime: A 2D Animation Optical Flow Dataset from 3D Model Rendering||    |[link](155.md)|
||2025.5.30|AdaHuman: Animatable Detailed 3D Human Generation with Compositional Multiview Diffusion|| 从单张真实场景图像生成高保真可动画3D头像   |[link](142.md)|
||2025.5.30|UniGeo: Taming Video Diffusion for Unified Consistent Geometry Estimation||  利用扩散模型先验知识辅助单目几何估计  |[link](145.md)|
||2025.5.30|LTM3D: Bridging Token Spaces for Conditional 3D Generation with Auto-Regressive Diffusion Framework|| 条件化3D形状生成   |[link](144.md)|
||2025.5.20|Vid2World: Crafting Video Diffusion Models to Interactive World Models|| 将预训练视频扩散模型迁移应用于交互式世界模型的通用方法  |[link](103.md)|
||2025.5.16|Infinigen-Sim: Procedural Generation of Articulated Simulation Assets|| Blender工具，可创建铰链资源  |[link](93.md)|
||2025.5.16|PoseBench3D: A Cross-Dataset Analysis Framework for 3D Human Pose Estimation|| HPE的标准化测试环境  |[link](95.md)|
||2025.5.15|TexTailor: Customized Text-aligned Texturing via Effective Resampling|| 文本给3D物体加纹理 |[link](85.md)|
||2025.5.13|ACT-R: Adaptive Camera Trajectories for 3D Reconstruction from Single Image|| 多视角的3D重建 |[link](81.md)|
||2025.5.12|Step1X-3D: Towards High-Fidelity and Controllable Generation of Textured 3D Assets||3D生成框架  |[link](75.md)|
||2025.5.12|Link to the Past: Temporal Propagation for Fast 3D Human Reconstruction from Monocular Video|| 单目视频实现快速3D穿衣人体重建 |[link](74.md)|
||2025.5.8|3D Scene Generation: A Survey||   |[link](62.md)|
||2025.5.7|Apply Hierarchical-Chain-of-Generation to Complex Attributes Text-to-3D Generation|| 文生3D模型 |[link](66.md)|
||2025.5.7|MeshGen: Generating PBR Textured Mesh with Render-Enhanced Auto-Encoder and Generative Data Augmentation|| 3D重建 |[link](58.md)|
||2025.5.7|Person-In-Situ: Scene-Consistent Human Image Insertion with Occlusion-Aware Pose Control||  将人体图像合成到场景图像中 |[link](54.md)|
||2025.5.3|Efficient 3D Full-Body Motion Generation from Sparse Tracking Inputs with Temporal Windows|| 稀疏输入，动作生成 |[link](42.md)|
||2025.5.1|JointDiT: Enhancing RGB-Depth Joint Modeling with Diffusion Transformers|| RGB图像与深度图进行联合生成 |[link](36.md)|
||2025.4.29|TesserAct: Learning 4D Embodied World Models||4D场景重建 |[link](22.md)|
||2025.4.28|AnimateAnywhere: Rouse the Background in Human Image Animation|| 基于人体视频生成运行背景|[link](17.md)|
||2025.4.25|Unify3D: An Augmented Holistic End-to-end Monocular 3D Human Reconstruction via Anatomy Shaping and Twins Negotiating|| 单目三维穿衣人体重建|[link](12.md)|
||2025.4.24|Dynamic Camera Poses and Where to Find Them||相机位姿估计|[link](2.md)|
||2025.4.24|Bolt: Clothing Virtual Characters at Scale||3D服装迁移适配|[link](3.md)|
||2025.4.24|Unveiling Hidden Vulnerabilities in Digital Human Generation via Adversarial Attacks||HPS攻击对抗|[link](5.md)|
||2025.4.23|HUG: Hierarchical Urban Gaussian Splatting with Block-Based Reconstruction|| 3D场景重建|[link](8.md)|
||2025.4.23|Gaussian Splatting is an Effective Data Generator for 3D Object Detection|| 3D物体放入2D场景|[link](9.md)|
||2025.4.23|Physically Consistent Humanoid Loco-Manipulation using Latent Diffusion Models||生成逼真的RGB人-物交互场景，以指导人形机器人的移动操作规划 |[link](7.md)|
||2025.4.22|SmallGS: Gaussian Splatting-based Camera Pose Estimation for Small-Baseline Videos||小基线视频的相机姿态估计 |[link](14.md)|


