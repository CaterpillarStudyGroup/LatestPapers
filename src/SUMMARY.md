- [Introduction](README.md)

# Abstract

- [  ](*.md)
- [  ](110.md)
- [  ](109.md)
- [  ](108.md)
- [EVA: Expressive Virtual Avatars from Multi-view Videos](107.md)
- [Interspatial Attention for Efficient 4D Human Video Generation](106.md)
- [Large-Scale Multi-Character Interaction Synthesis](105.md)
- [Hunyuan-Game: Industrial-grade Intelligent Game Creation Model](104.md)
- [Vid2World: Crafting Video Diffusion Models to Interactive World Models](103.md)
- [MGStream: Motion-aware 3D Gaussian for Streamable Dynamic Scene Reconstruction](102.md)
- [LMP: Leveraging Motion Prior in Zero-Shot Video Generation with Diffusion Transformer](101.md)
- [Video-GPT via Next Clip Diffusion](100.md)
- [MonoMobility: Zero-Shot 3D Mobility Analysis from Monocular Videos](99.md)
- [RoPECraft: Training-Free Motion Transfer with Trajectory-Guided RoPE Optimization on Diffusion Transformers](98.md)
- [UniHM: Universal Human Motion Generation with Object Interactions in Indoor Scenes](97.md)
- [FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance](96.md)
- [PoseBench3D: A Cross-Dataset Analysis Framework for 3D Human Pose Estimation](95.md)
- [Robust Photo-Realistic Hand Gesture Generation: from Single View to Multiple View](94.md)
- [Infinigen-Sim: Procedural Generation of Articulated Simulation Assets](93.md)
- [MoCLIP: Motion-Aware Fine-Tuning and Distillation of CLIP for Human Motion Generation](92.md)
- [Towards Robust and Controllable Text-to-Motion via Masked Autoregressive Diffusion](91.md)
- [Locality Sensitive Avatars From Video](90.md)
- [Dyadic Mamba: Long-term Dyadic Human Motion Synthesis](89.md)
- [HGMÂ³: Hierarchical Generative Masked Motion Modeling with Hard Token Mining](87.md)
- [MTVCrafter: 4D Motion Tokenization for Open-World Human Image Animation](86.md)
- [TexTailor: Customized Text-aligned Texturing via Effective Resampling](85.md)
- [Generating time-consistent dynamics with discriminator-guided image diffusion models](84.md)
- [Text-driven Motion Generation: Overview, Challenges and Directions](83.md)
- [CameraCtrl: Enabling Camera Control for Video Diffusion Models](82.md)
- [ACT-R: Adaptive Camera Trajectories for 3D Reconstruction from Single Image](81.md)
- [M3G: Multi-Granular Gesture Generator for Audio-Driven Full-Body Human Motion Synthesis](80.md)
- [SplineGS: Learning Smooth Trajectories in Gaussian Splatting for Dynamic Scene Reconstruction](79.md)
- [CyberHost: A One-stage Diffusion Framework for Audio-driven Talking Body Generation](78.md)
- [PhysAnimator: Physics-Guided Generative Cartoon Animation](77.md)
- [Sketch2Anim: Towards Transferring Sketch Storyboards into 3D Animation](76.md)
- [Step1X-3D: Towards High-Fidelity and Controllable Generation of Textured 3D Assets](75.md)
- [Link to the Past: Temporal Propagation for Fast 3D Human Reconstruction from Monocular Video](74.md)
- [ShotAdapter: Text-to-Multi-Shot Video Generation with Diffusion Models](73.md)
- [Human Motion Prediction via Test-domain-aware Adaptation with Easily-available Human Motions Estimated from Videos](72.md)
- [MAGE:A Multi-stage Avatar Generator with Sparse Observations](71.md)
- [DiffLocks: Generating 3D Hair from a Single Image using Diffusion Models](70.md)
- [TeGA: Texture Space Gaussian Avatars for High-Resolution Dynamic Head Modeling](69.md)
- [Anymate: A Dataset and Baselines for Learning 3D Object Rigging](68.md)
- [ReactDance: Progressive-Granular Representation for Long-Term Coherent Reactive Dance Generation](67.md)
- [Apply Hierarchical-Chain-of-Generation to Complex Attributes Text-to-3D Generation](66.md)
- [Humanise: Language-conditioned human motion generation in 3d scenes](65.md)
- [Synthesizing Diverse Human Motions in 3D Indoor Scenes](64.md)
- [Move as You Say, Interact as You Can:Language-guided Human Motion Generation with Scene Affordance](63.md)
- [3D Scene Generation: A Survey](62.md)
- [SVAD: From Single Image to 3D Avatar via Synthetic Data Generation with Video Diffusion and Data Augmentation](61.md)
- [ReAlign: Bilingual Text-to-Motion Generation via Step-Aware Reward-Guided Alignment](59.md)
- [MeshGen: Generating PBR Textured Mesh with Render-Enhanced Auto-Encoder and Generative Data Augmentation](58.md)
- [TokenHSI: Unified Synthesis of Physical Human-Scene Interactions through Task Tokenization](57.md)
- [ELGAR: Expressive Cello Performance Motion Generation for Audio Rendition](56.md)
- [PARC: Physics-based Augmentation with Reinforcement Learning for Character Controllers](55.md)
- [Person-In-Situ: Scene-Consistent Human Image Insertion with Occlusion-Aware Pose Control](54.md)
- [PrimitiveAnything: Human-Crafted 3D Primitive Assembly Generation with Auto-Regressive Transformer](53.md)
- [Bridging Geometry-Coherent Text-to-3D Generation with Multi-View Diffusion Priors and Gaussian Splatting](52.md)
- [FlexiAct: Towards Flexible Action Control in Heterogeneous Scenarios](51.md)
- [Real-Time Person Image Synthesis Using a Flow Matching Model](50.md)
- [Polar Coordinate-Based 2D Pose Prior with Neural Distance Field](49.md)
- [PAHA: Parts-Aware Audio-Driven Human Animation with Diffusion Model](48.md)
- [GUAVA: Generalizable Upper Body 3D Gaussian Avatar](47.md)
- [DualReal: Adaptive Joint Training for Lossless Identity-Motion Fusion in Video Customization](46.md)
- [SignSplat: Rendering Sign Language via Gaussian Splatting](45.md)
- [MVHumanNet++: A Large-scale Dataset of Multi-view Daily Dressing Human Captures with Richer Annotations for 3D Human Digitization ](44.md)
- [Co$^{3}$Gesture: Towards Coherent Concurrent Co-speech 3D Gesture Generation with Interactive Diffusion](43.md)
- [Efficient 3D Full-Body Motion Generation from Sparse Tracking Inputs with Temporal Windows](42.md)
- [Model See Model Do: Speech-Driven Facial Animation with Style Control](41.md)
- [3D Human Pose Estimation via Spatial Graph Order Attention and Temporal Body Aware Transformer](40.md)
- [GENMO: A GENeralist Model for Human MOtion](37.md)
- [JointDiT: Enhancing RGB-Depth Joint Modeling with Diffusion Transformers](36.md)
- [Eye2Eye: A Simple Approach for Monocular-to-Stereo Video Synthesis](35.md)
- [T2VPhysBench: A First-Principles Benchmark for Physical Consistency in Text-to-Video Generation](34.md)
- [Direct Motion Models for Assessing Generated Videos](33.md)
- [Real-Time Animatable 2DGS-Avatars with Detail Enhancement from Monocular Videos](32.md)
- [CoCoDiff: Diversifying Skeleton Action Features via Coarse-Fine Text-Co-Guided Latent Diffusion](31.md)
- [Common3D: Self-Supervised Learning of 3D Morphable Models for Common Objects in Neural Feature Space](30.md)
- [HoloTime: Taming Video Diffusion Models for Panoramic 4D Scene Generation](29.md)
- [MagicPortrait: Temporally Consistent Face Reenactment with 3D Geometric Guidance](28.md)
- [ReVision: High-Quality, Low-Cost Video Generation with Explicit 3D Physics Modeling for Complex Motion and Interaction](27.md)
- [Efficient Listener: Dyadic Facial Motion Synthesis via Action Diffusion](25.md)
- [Creating Your Editable 3D Photorealistic Avatar with Tetrahedron-constrained Gaussian Splatting](24.md)
- [SoccerDiffusion: Toward Learning End-to-End Humanoid Robot Soccer from Gameplay Recordings](23.md)
- [TesserAct: Learning 4D Embodied World Models](22.md)
- [EfficientHuman: Efficient Training and Reconstruction of Moving Human using Articulated 2D Gaussian](21.md)
- [Joint Optimization of Neural Radiance Fields and Continuous Camera Motion from a Monocular Video](20.md)
- [Sketch2Anim: Towards Transferring Sketch Storyboards into 3D Animation](19.md)
- [HumMorph: Generalized Dynamic Human Neural Fields from Few Views](18.md)
- [AnimateAnywhere: Rouse the Background in Human Image Animation](17.md)
- [Generative AI for Character Animation: A Comprehensive Survey of Techniques, Applications, and Future Directions](16.md)
- [ActionArt: Advancing Multimodal Large Models for Fine-Grained Human-Centric Video Understanding](15.md)
- [SmallGS: Gaussian Splatting-based Camera Pose Estimation for Small-Baseline Videos](14.md)
- [STP4D: Spatio-Temporal-Prompt Consistent Modeling for Text-to-4D Gaussian Splatting](13.md)
- [Unify3D: An Augmented Holistic End-to-end Monocular 3D Human Reconstruction via Anatomy Shaping and Twins Negotiating](12.md)
- [SSD-Poser: Avatar Pose Estimation with State Space Duality from Sparse Observations](11.md)
- [PIN-WM: Learning Physics-INformed World Models for Non-Prehensile Manipulation](10.md)
- [Gaussian Splatting is an Effective Data Generator for 3D Object Detection](9.md)
- [HUG: Hierarchical Urban Gaussian Splatting with Block-Based Reconstruction](8.md)
- [Physically Consistent Humanoid Loco-Manipulation using Latent Diffusion Models](7.md)
- [PMG: Progressive Motion Generation via Sparse Anchor Postures Curriculum Learning](6.md)
- [Unveiling Hidden Vulnerabilities in Digital Human Generation via Adversarial Attacks](5.md)
- [PICO: Reconstructing 3D People In Contact with Objects](4.md)
- [Bolt: Clothing Virtual Characters at Scale](3.md)
- [Dynamic Camera Poses and Where to Find Them](2.md)
- [3DV-TON: Textured 3D-Guided Consistent Video Try-on via Diffusion Models](1.md)