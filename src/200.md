VideoMAR: Autoregressive Video Generatio with Continuous Tokens


基于掩码的自回归模型在连续空间中已展现出卓越的图像生成能力。然而，其在视频生成方面的潜力仍未得到充分探索。本文提出 **VideoMAR**，一个简洁高效的纯解码器自回归图像到视频模型，它使用连续标记（continuous tokens），融合了时间维度上的逐帧生成和空间维度上的掩码生成。   

我们首先确立了时间因果性和空间双向性作为视频自回归模型的首要原则，并提出了下一帧扩散损失（next-frame diffusion loss）来整合掩码与视频生成。此外，长序列自回归建模的巨大成本和难度是一个基础但关键的问题。为此，我们提出了**时间维度上由短及长的课程学习**（temporal short-to-long curriculum learning）和**空间维度上渐进分辨率训练**（spatial progressive resolution training），并在推理时采用**渐进温度策略**（progressive temperature strategy）以减轻累积误差。    

此外，VideoMAR 将语言模型的多种独特能力复现到了视频生成领域。得益于其**时间维度上的 KV 缓存复用**（simultaneous temporal-wise KV cache）和**空间维度上的并行生成**（spatial-wise parallel generation），它天然具备高效率；并且通过**3D 旋转位置编码**（3D rotary embeddings），它展现出空间和时间外推能力。    

在 VBench-I2V 基准测试中，VideoMAR 超越了之前的最先进模型（Cosmos I2V），同时所需参数量（$9.3\%$）、训练数据量（$0.5\%$）和 GPU 资源（$0.2\%$）均显著减少。    
 