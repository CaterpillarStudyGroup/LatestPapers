Toward Rich Video Human-Motion2D Generation


生成逼真且可控的人体动作，尤其是那些涉及丰富的多角色交互的动作，由于数据稀缺以及人际互动动态建模的复杂性，仍然是一个重大挑战。为应对这些限制，我们首先引入了一个新的大规模、信息丰富的视频人体动作2D数据集（Motion2D-Video-150K），该数据集包含**15万个视频序列**。Motion2D-Video-150K的特点是其**平衡分布**了多样的单角色动作，以及**关键的双角色交互动作**，每个视频均配有详细的文本描述。   

基于此数据集，我们提出了一种新颖的、基于扩散模型的丰富视频人体动作2D生成模型（**RVHM2D**）。RVHM2D采用了一种增强的文本条件机制，该机制利用**双文本编码器（CLIP-L/B）或T5-XXL**，并结合了**全局和局部特征**。我们设计了一种**两阶段训练策略**：模型首先使用标准的扩散目标进行训练，然后使用**基于FID指标的奖励进行强化学习微调**，以进一步提升动作的逼真度和文本对齐度。    

大量实验表明，RVHM2D在Motion2D-Video-150K基准测试上，无论是生成单角色还是交互式双角色场景，都取得了**领先的性能**。   