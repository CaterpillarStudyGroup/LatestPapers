AniCrafter: Customizing Realistic Human-Centric Animation via Avatar-Background Conditioning in Video Diffusion Models


视频扩散模型的最新进展显著提升了角色动画技术。然而，当前方法依赖于诸如 DWPose 或 SMPL-X 等基础结构条件来驱动角色图像动画，这限制了它们在具有动态背景或复杂人体姿态的开放域场景中的有效性。为此，我们提出 **AniCrafter**，这是一个基于扩散模型、以人物为中心的动画模型。它能够无缝地将给定角色集成并动画化到开放域的动态背景中，同时遵循给定的人体运动序列。我们的模型建立在尖端的图像到视频(I2V)扩散架构之上，并融入了一种创新的“角色-背景”联合条件控制机制。该机制将开放域以人物为中心的动画重新定义为一项**修复任务**，从而生成更稳定、更通用的动画输出。实验结果表明，我们的方法具有显著优势。代码将在 <https://github.com/MyNiuuu/AniCrafter> 公开。   