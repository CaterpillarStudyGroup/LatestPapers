SignAligner: Harmonizing Complementary Pose Modalities for Coherent Sign Language Generation


**手语生成**的目标是基于口语生成多样化的手语表征。然而，由于手语本身的复杂性——包含精细的手势、面部表情和身体动作——实现逼真且自然的生成仍是一项重大挑战。   

在本研究中，我们引入了 **PHOENIX14T+**，这是广泛使用的 RWTH-PHOENIX-Weather 2014T 数据集的一个扩展版本，新增了三种手语表征：**姿势 (Pose)**、**Hamer** 和 **Smplerx**。同时，我们提出了一种用于逼真手语生成的新方法——**SignAligner**。该方法包含三个阶段：**文本驱动的姿态模态协同生成**、**多模态在线协作校正**以及**逼真的手语视频合成**。    

1.  **文本驱动的姿态模态协同生成：** 通过融入文本语义信息，我们设计了一个联合手语生成器，用于同时生成姿势坐标、手势动作和身体运动。基于 Transformer 架构的文本编码器提取语义特征，而跨模态注意力机制则整合这些特征，生成多样化的手语表征，确保模态特征的准确映射并控制其多样性。   
2.  **多模态在线协作校正：** 引入在线协作校正机制，利用动态损失加权策略和跨模态注意力来精炼生成的姿态模态。这促进了不同模态间信息的互补，消除了时空冲突，并确保了语义连贯性和动作一致性。   
3.  **逼真的手语视频合成：** 校正后的姿态模态被输入到一个预训练的视频生成网络中，最终生成高保真的手语视频。   

大量实验表明，SignAligner 显著提升了生成手语视频的**准确性**和**表现力**。    