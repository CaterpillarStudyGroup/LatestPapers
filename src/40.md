3D Human Pose Estimation via Spatial Graph Order Attention and Temporal Body Aware Transformer

当前，Transformer和图卷积网络(GCN)是三维人体姿态估计的主流技术。然而，基于Transformer的方法在使用骨架表征时要么忽略了关节之间的空间邻域关系，要么在骨架序列建模中忽视了局部关节运动的时序模式；而基于GCN的方法则常常未能构建姿态特异性表征。为解决这些问题，我们提出一种新方法：利用GCN的图建模能力，通过不同阶数的多图结构表征每个骨架，并引入新型图阶注意力模块动态强化各关节最具代表性的阶数特征。通过提出的时序身体感知Transformer对序列空间特征进行进一步处理，该模块在建模序列全局身体特征依赖关系时，能够感知关节间跨骨架的局部特征关联。鉴于我们的三维姿态输出与序列中心二维姿态对齐，我们改进了自注意力机制使其聚焦中心姿态特征，并沿序列首尾方向逐步弱化关注强度。在Human3.6m、MPI-INF-3DHP和HumanEva-I数据集上的大量实验验证了方法的有效性。代码和模型已在Github开源。