Real-Time Person Image Synthesis Using a Flow Matching Model

姿势引导人物图像合成(Pose-Guided Person Image Synthesis，PGPIS)是指根据目标姿势和源图像生成逼真人物图像的技术。该任务在手语视频生成、AR/VR、游戏和直播等实际应用中发挥着关键作用。在这些场景中，实时PGPIS技术对于提供即时视觉反馈和维持用户沉浸感至关重要。然而，由于从多样化和动态的人体姿势合成高保真图像的复杂性，实现实时性能仍然是一个重大挑战。近年来基于扩散模型的方法在PGPIS中展现出令人印象深刻的图像质量，但其缓慢的采样速度阻碍了在时间敏感场景中的部署。这种延迟在需要快速图像更新的任务(如直播中生成手语视频)中尤为明显。因此，开发快速可靠的PGPIS模型是实现实时交互系统的关键步骤。

为应对这一挑战，我们提出了一种基于流匹配(Flow Matching，FM)的生成模型。该方法能够实现更快、更稳定、更高效的训练和采样过程。此外，所提出的模型支持条件生成并可在潜在空间运行，使其特别适用于对速度和质量都有严格要求的实时PGPIS应用。我们在广泛使用的DeepFashion数据集上对提出的流匹配实时人物图像合成模型(Real-Time Person Image Synthesis Using a Flow Matching Model，RPFM)进行了评估。实验结果表明，RPFM在保持与最先进模型相当性能的同时，实现了接近实时的采样速度。该方法通过略微但可接受的生成图像准确性降低，换取了生成速度两倍以上的提升，从而确保了实时性能。