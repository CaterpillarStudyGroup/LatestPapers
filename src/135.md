LatentMove: Towards Complex Human Movement Video Generation 


**图像到视频(I2V)生成**旨在从单张参考图像生成逼真的运动序列。尽管现有方法展现出较强的时间一致性，但在处理**复杂、非重复的人体运动**时往往效果不佳，导致出现“不自然变形”。为解决此问题，我们提出了**LatentMove**，这是一个专门为高度动态的人体动画量身定制的、**基于DiT(扩散Transformer)的框架**。我们的架构融合了一个**条件控制分支**以及**可学习的面部/身体标记(tokens)**，以保持帧间一致性以及细粒度细节。我们引入了**Complex-Human-Videos (CHV)** 数据集，该数据集包含多样且富有挑战性的人体动作，旨在**评估I2V系统的鲁棒性**。我们还引入了两个新的**评估指标**，用于衡量生成视频与其真实视频(ground truth)在**光流(flow)** 和**轮廓(silhouette)一致性**上的差异。实验结果表明，LatentMove**显著提升了人体动画质量**——尤其是在处理快速、复杂动作时——从而**推动了I2V生成的边界**。相关代码、CHV数据集以及评估指标将在 <https://github.com/-- >开放。     