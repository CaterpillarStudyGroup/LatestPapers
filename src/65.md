Humanise: Language-conditioned human motion generation in 3d scenes

由于现有人-场景交互（HSI）数据集在规模和语义上的局限性，学习生成多样化、场景感知且目标导向的3D人体运动仍面临挑战。这些数据集普遍存在规模有限、质量平庸且语义信息匮乏的问题。为填补这一空白，我们通过将捕捉到的人体运动序列与多样化的3D室内场景对齐，提出了一个大规模且富含语义的合成HSI数据集HUMANISE。我们采用自动化方法为对齐后的运动数据标注语言描述，这些描述不仅包含动作信息，还明确指向具体交互物体（例如"坐在书桌旁的扶手椅上"）。由此，HUMANISE开启了一个全新的生成任务 —— 基于语言条件的3D场景人体运动生成。该任务的挑战性在于需要同时对3D场景、人体运动和自然语言进行联合建模。为此，我们提出了一种创新的场景-语言条件生成模型，能够生成与指定物体进行目标交互的3D人体运动。实验结果表明，该模型可在3D场景中生成多样化且语义一致的人体运动。


