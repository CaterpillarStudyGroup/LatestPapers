Multimodal Generative AI with Autoregressive LLMs for Human Motion Understanding and Generation: A Way Forward


本文对利用多模态生成式人工智能(GenAI)和自回归大语言模型(LLM)进行人体运动理解与生成的研究进行了深入综述，探讨了新兴方法、架构及其在推动逼真且多样化运动合成方面的潜力。本研究专注于文本与运动两种模态，探究了文本描述如何指导生成复杂、类人的运动序列。文章分析了多种生成方法(包括自回归模型、扩散模型、生成对抗网络(GANs)、变分自编码器(VAEs)以及基于Transformer的模型)在运动质量、计算效率和适应性方面的优势与局限。重点探讨了文本条件运动生成领域的最新进展，即利用文本输入来更精确地控制和优化运动输出。通过整合大语言模型(LLMs)，进一步增强了这些模型的能力，实现了指令与运动之间的语义对齐，从而提升了连贯性和情境相关性。本系统性综述强调了文本到运动(text-to-motion)的GenAI和LLM架构在医疗保健、人形机器人、游戏、动画和辅助技术等应用中的变革潜力，同时也探讨了在生成高效且逼真人运动方面持续存在的挑战。 