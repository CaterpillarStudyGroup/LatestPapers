IKMo: Image-Keyframed Motion Generation with Trajectory-Pose Conditioned Motion Diffusion Model

**现有基于轨迹与姿态输入的人体运动生成方法**通常对这两种模态进行全局处理，导致输出结果次优。本文提出 **IKMo**（基于图像关键帧的运动生成方法），这是一种基于扩散模型的运动生成方法，其核心在于**解耦轨迹与姿态输入**。轨迹和姿态输入经过一个**两阶段条件化框架**进行处理：    
1. **第一阶段**：应用专门的优化模块对输入进行精细化处理。   
2. **第二阶段**：轨迹和姿态**并行**通过一个**轨迹编码器（Trajectory Encoder）**和一个**姿态编码器（Pose Encoder）**进行编码。随后，一个**运动控制网络（ControlNet）**处理融合后的轨迹与姿态数据，引导生成具有**高空间保真度与语义保真度**的运动。   

基于 HumanML3D 和 KIT-ML 数据集的实验结果表明，在轨迹-关键帧约束下，所提方法在所有指标上均优于现有最优方法。此外，我们实现了**基于多模态大语言模型（MLLM）的智能体**来预处理模型输入。给定用户提供的文本和关键帧图像，这些智能体能够提取运动描述、关键帧姿态和轨迹作为优化后的输入，输入到运动生成模型中。我们进行了包含 10 名参与者的用户研究，实验结果证明，基于 MLLM 的智能体预处理使生成的运动更符合用户预期。我们相信，所提出的方法显著提升了扩散模型在运动生成方面的**保真度与可控性**。   