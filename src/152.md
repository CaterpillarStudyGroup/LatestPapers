Controllable Human-centric Keyframe Interpolation with Generative Prior


**现有**的插帧方法利用预训练的视频扩散模型先验知识，在稀疏采样的关键帧之间生成中间帧。**然而**，由于缺乏三维几何指导，这些方法在处理复杂、关节式的人体运动时难以生成合理的插帧效果，并且对合成动态效果的控制能力有限。    

**本文中**，我们提出了 **PoseFuse3D关键帧插值器(PoseFuse3D-KI)**，这是一种新颖的框架，它将三维人体引导信号集成到扩散过程中，以实现**可控的人体中心关键帧插值(Controllable Human-centric Keyframe Interpolation, CHKI)**。为了给插帧提供丰富的空间和结构线索，我们的三维感知控制模型 **PoseFuse3D** 包含两个核心组件：一个**新颖的 SMPL-X 编码器**，负责将三维几何和形状信息转换到二维潜在条件空间；以及一个**融合网络**，用于将这些三维线索与二维姿态嵌入进行整合。    

**为了评估**，我们构建了 **CHKI-Video** 数据集，这是一个包含二维姿态和三维 SMPL-X 参数标注的新数据集。**实验表明**，PoseFuse3D-KI 在 CHKI-Video 数据集上始终优于当前最先进的基线方法，峰值信噪比(PSNR)提升了 9%，学习感知图像块相似度(LPIPS)降低了 38%。**全面的消融实验**证明，我们的 PoseFuse3D 模型有效提升了插帧的保真度。   
