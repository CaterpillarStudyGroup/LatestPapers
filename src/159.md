SinGS: Animatable Single-Image Human Gaussian Splats with Kinematic Priors



尽管当代单图像3D人体重建在精确估计几何形状方面取得了显著进展，但创建高质量、高效且**可驱动**的三维化身仍然是一个**开放挑战**。两个关键障碍持续存在：**观测不完整**和**3D先验不一致**。为了应对这些挑战，我们提出了SinGS，旨在实现高质量且高效的可驱动三维化身重建。   

SinGS的核心包含两个关键组件：**运动学人体扩散 (Kinematic Human Diffusion)** 和**几何保持的3D高斯泼溅 (Geometry-Preserving 3D Gaussian Splatting)**。前者是一个基础人体模型，它在姿态空间内进行**采样**，生成一个高度**3D一致**且高质量的人体图像序列，从而推断**未观测视角**并提供**运动学先验**。后者是一个重建系统，即使在**不完美先验**条件下，也能重建出**紧凑**、**高质量**的3D化身。这是通过一种新颖的**语义拉普拉斯正则化 (semantic Laplacian regularization)** 和一种**几何保持的密度控制策略 (geometry-preserving density control strategy)** 实现的，该策略能够**精确且紧凑地组装3D基元 (3D primitives)**。   

大量实验表明，SinGS能够实现**逼真的、可驱动的人体重建**，同时保持了**高质量**和**高推理效率（高达70FPS）**。   