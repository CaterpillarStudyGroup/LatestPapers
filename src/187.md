Aligned Novel View Image and Geometry Synthesis via Cross-modal Attention Instillation


我们提出了一种基于扩散模型的框架，通过**扭曲修复方法（warping-and-inpainting methodology）**实现对齐的新视角图像与几何结构生成。不同于以往需要密集姿态图像或局限于域内视角的、嵌入姿态的生成模型的方法，我们的方法**利用现成的几何预测器（off-the-shelf geometry predictors）**从参考图像预测部分几何结构，并将新视角合成（novel-view synthesis）**表述为图像和几何结构的修复任务（inpainting task）**。   

为确保生成的图像与几何结构之间精确对齐，我们提出了**跨模态注意力蒸馏（cross-modal attention distillation）**。在训练和推理过程中，将图像扩散分支（image diffusion branch）的注意力图（attention maps）**注入（injected into）**一个并行的几何扩散分支（geometry diffusion branch）。这种**多任务方法（multi-task approach）**产生了**协同效应（synergistic effects）**，既促进了几何鲁棒的图像合成（geometrically robust image synthesis），也实现了边界清晰的几何预测（well-defined geometry prediction）。   

我们进一步引入了**邻近网格条件（proximity-based mesh conditioning）**，以整合深度和法线线索（depth and normal cues）。该方法在点云之间进行插值（interpolating between point cloud），并**过滤错误预测的几何结构（filtering erroneously predicted geometry）**，防止其影响生成过程。   

实验表明，我们的方法在一系列未见场景（unseen scenes）上，针对图像和几何结构均实现了**高保真的外推式视图合成（high-fidelity extrapolative view synthesis）**；在插值设置（interpolation settings）下提供了具有竞争力的重建质量（competitive reconstruction quality）；并能生成几何对齐的彩色点云（geometrically aligned colored point clouds），用于全面的三维补全（comprehensive 3D completion）。    

项目主页位于：<https://cvlab-kaist.github.io/MoAI>。   