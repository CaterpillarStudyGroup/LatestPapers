SplArt: Articulation Estimation and Part-Level Reconstruction with 3D Gaussian Splatting


**重建日常环境中普遍存在的铰接物体**对于增强现实/虚拟现实和机器人技术应用至关重要。然而，现有方法面临可扩展性限制(需要3D监督或昂贵的标注)、鲁棒性问题(易陷入局部最优)以及渲染缺陷(速度慢或缺乏照片级真实感)。我们提出了 **SplArt**，这是一个自监督、类别无关的框架。它利用3D高斯溅射(3DGS)技术，仅需在不同关节状态下捕获的两组带位姿的RGB图像，即可重建铰接物体并推断其运动学，从而能够对新颖视角和关节状态进行实时照片级真实感的渲染。    

SplArt通过为每个高斯点引入一个**可微分的运动参数**来增强3DGS，实现了精细化的部件分割。该框架采用**多阶段优化策略**，逐步处理重建、部件分割和关节估计，显著提高了鲁棒性和准确性。SplArt充分利用**几何自监督**，无需3D标注或特定类别的先验知识，即能有效应对各种具有挑战性的场景。在既有基准和新提出的基准上进行的评估，以及使用手持RGB相机在真实场景中的应用，均证明了SplArt的**领先性能**和**实际应用价值**。代码已在 <https://github.com/ripl/splart> 公开。   