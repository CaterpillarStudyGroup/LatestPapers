SyncTalk++: High-Fidelity and Efficient Synchronized Talking Heads Synthesis Using Gaussian Splatting


**实现高度同步的真实语音驱动说话头视频合成是一项重大挑战。** 一个逼真的说话头需要人物身份、唇部动作、面部表情和头部姿态的同步协调。缺乏这些同步性是导致结果不真实的一个根本性缺陷。为解决这一被视作创建逼真说话头过程中“魔鬼”的关键同步问题，我们提出了 **SyncTalk++**。该方案包含一个基于高斯溅射的**动态肖像渲染器**，以确保人物身份的一致保持；以及一个**唇语同步控制器**，用于对齐唇部动作与语音，并创新性地利用**3D面部混合变形模型**来重建精准的面部表情。为确保自然的头部运动，我们提出了**头部同步稳定器**，通过优化头部姿态来提升稳定性。此外，SyncTalk++ 通过整合**表情生成器**和**躯干修复器**，增强了对分布外音频的鲁棒性——前者生成与语音匹配的面部表情，后者则修复出无缝衔接的躯干区域。我们的方法在帧间视觉细节上保持了一致性与连续性，并显著提升了渲染速度和质量，最高可达**每秒101帧**。大量的实验和用户研究表明，SyncTalk++ 在同步性和真实感方面均优于现有最先进的方法。我们推荐观看补充视频：<https://ziqiaopeng.github.io/synctalk++>。    
