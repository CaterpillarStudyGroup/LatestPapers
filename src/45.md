SignSplat: Rendering Sign Language via Gaussian Splatting

通过高斯泼溅实现条件性人体渲染的现有最先进方法通常侧重于从多视角捕捉简单身体动作(如舞蹈或行走)。然而对于更复杂的用例(如手语)，我们更关注手部和面部细微且复杂的运动，而非大幅度的身体动作。由于捕捉手语多视角数据的复杂性，构建高保真模型的问题进一步加剧。解决方案在于更好地利用序列数据，通过挖掘时间变化性来克服有限视角信息带来的挑战。但基于序列数据的学习需要极其精确且一致的模型拟合，以确保复杂运动中外观的一致性。我们重点研究如何通过约束网格参数，构建能够从少量视角建模人体细微运动的高斯泼溅框架。我们对高斯参数施加正则化技术以缓解过拟合和渲染伪影问题。此外，提出了一种新的自适应控制方法来致密化高斯分布并修剪网格表面上的泼溅点。为验证方法的准确性，我们基于神经机器翻译方法构建手语拼接技术，渲染出新颖的手语视频序列。在基准数据集上，我们的方法达到业界领先水平；对于高度关节化和复杂的手语动作，其表现显著优于现有方法。