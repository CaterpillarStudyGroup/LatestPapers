DualReal: Adaptive Joint Training for Lossless Identity-Motion Fusion in Video Customization

基于预训练大规模模型的定制化文生视频技术近年来通过聚焦身份与运动一致性获得了广泛关注。现有方法通常采用孤立的定制范式，即单独定制主体身份或运动动态。然而，这种范式完全忽视了身份与运动之间固有的相互约束和协同依存关系，导致生成过程中身份与运动冲突不断积累并系统性劣化。为此，我们提出了DualReal创新框架，通过自适应联合训练在双维度间协作构建相互依赖关系。具体而言，DualReal包含两个核心单元：(1)双重感知适配单元通过动态选择训练阶段(身份或运动)，在冻结维度的先验指导下学习当前信息，并采用正则化策略避免知识泄露；(2)阶段混合控制器利用去噪阶段和扩散Transformer深度的对应关系，以自适应粒度指导不同维度，在多个阶段规避冲突，最终实现身份与运动模式的无损融合。我们构建了比现有方法更全面的评测基准，实验结果表明DualReal在CLIP-I和DINO-I指标上平均提升21.7%和31.8%，在几乎所有运动质量指标上均达到最优性能。   

