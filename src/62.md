3D Scene Generation: A Survey

三维场景生成旨在合成具有空间结构、语义信息丰富且逼真的虚拟环境，其应用涵盖沉浸式媒体、机器人、自动驾驶和具身智能等领域。早期基于程序化规则的方法虽具备可扩展性，但生成多样性受限。随着深度生成模型(如生成对抗网络、扩散模型)和三维表征技术(如神经辐射场、三维高斯分布)的突破性进展，研究者得以学习真实场景分布规律，显著提升了生成结果的真实感、多样性和视角一致性。以扩散模型为代表的创新方法通过将三维场景生成重构为图像或视频合成问题，有效弥合了场景合成与真实感渲染之间的鸿沟。本文系统梳理了该领域前沿进展，将现有方法归纳为四大范式：程序化生成、基于神经三维的生成、基于图像的生成和基于视频的生成，深入剖析了各范式的技术原理、优劣权衡及代表性成果。同时，本文详细评述了常用数据集、评估体系及下游应用，并针对生成能力、三维表征、数据标注和评估方法等核心挑战展开讨论，提出未来发展方向包括：提升生成质量、开发物理感知与交互式生成技术、构建感知-生成一体化模型等。本综述系统整合了三维场景生成领域的最新突破，并展望了生成式人工智能、三维视觉与具身智能交叉融合的创新方向。为追踪动态发展，我们维护了最新项目页面：<https://github.com/hzxie/Awesome-3D-Scene-Generation>。