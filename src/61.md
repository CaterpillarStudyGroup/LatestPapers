SVAD: From Single Image to 3D Avatar via Synthetic Data Generation with Video Diffusion and Data Augmentation

从单张图像创建高质量可驱动的3D人体化身仍然是计算机视觉领域的重要挑战，这源于从单一视角重建完整3D信息的内在困难。现有方法面临明显局限：3D高斯泼溅(3DGS)方法虽能生成高质量结果，但需要多视角或视频序列输入；而视频扩散模型虽然能从单张图像生成动画，但在保持一致性和身份特征方面存在不足。我们提出SVAD方法，通过整合现有技术的互补优势突破这些限制。该方法通过视频扩散生成合成训练数据，采用身份特征保留和图像修复模块进行增强，并利用优化后的数据训练3DGS化身。综合评估表明，SVAD在保持身份一致性和跨新姿态/视角的细节呈现方面优于当前最先进的单图方法，同时具备实时渲染能力。通过构建数据增强流程，我们克服了传统3DGS方法对密集单目或多视图训练数据的依赖。大量定量与定性对比实验显示，本方法在多项指标上均超越基线模型。通过有效结合扩散模型的生成能力与3DGS的高质量输出及渲染效率，我们的工作为单图输入的高保真化身生成建立了新范式。