DreamDance: Animating Character Art via Inpainting Stable Gaussian Worlds


本文提出 DreamDance，一种新颖的角色美术动画框架，能够基于精确的相机轨迹生成稳定、一致的角色与场景运动。为实现此目标，我们将动画任务重新构建为两个基于修复的步骤：相机感知场景修复(Camera-aware Scene Inpainting)和姿态感知视频修复(Pose-aware Video Inpainting)。   

第一步利用预训练的图像修复模型，从参考美术作品生成多视角场景图像，并优化一个稳定的大规模高斯场(Gaussian field)，从而实现基于相机轨迹的粗略背景视频渲染。然而，渲染出的视频较为粗糙且仅包含场景运动。   

为解决此问题，第二步训练一个姿态感知视频修复模型，该模型将动态角色注入场景视频中，同时提升背景质量。具体来说，该模型是一个基于 DiT(Diffusion Transformer)的视频生成模型，采用门控策略(gating strategy)自适应地将角色的外观和姿态信息融合到基础背景视频中。   

通过大量实验，我们证明了 DreamDance 的有效性和强泛化性(generalizability)，能够生成具有显著相机动态效果的高质量、一致性角色动画。   