GenHOI: Generalizing Text-driven 4D Human-Object Interaction Synthesis for Unseen Objects


尽管扩散模型和大规模运动数据集推动了文本驱动的人体动作生成技术的发展，但将这些进展扩展到四维（4D）人-物交互（HOI）领域仍然充满挑战，这主要归因于大规模 4D HOI 数据集的稀缺性。在我们的研究中，我们提出了 GenHOI，一个新颖的两阶段框架，旨在实现两个关键目标：1) 对未见过的物体具有泛化能力；2) 合成高保真度的 4D HOI 序列。   

在我们框架的初始阶段，我们采用 **物体锚点网络 (Object-AnchorNet)** 来为未见过的物体重建稀疏的 3D HOI 关键帧。该网络仅需从 3D HOI 数据集中学习即可，从而减少了对大规模 4D HOI 数据集的依赖。   

随后，在第二阶段，我们引入了 **接触感知扩散模型 (ContactDM)**，将稀疏的 3D HOI 关键帧无缝地插值成时间一致性的密集 4D HOI 序列。为了提高生成的 4D HOI 序列质量，我们在 ContactDM 中提出了一种新颖的 **接触感知编码器 (Contact-Aware Encoder)** 来提取人-物接触模式，以及一种新颖的 **接触感知 HOI 注意力机制 (Contact-Aware HOI Attention)**，将接触信号有效地整合到扩散模型中。   

实验结果表明，我们在公开可用的 OMOMO 和 3D-FUTURE 数据集上取得了最先进的结果，展现了对未见物体的强大泛化能力，同时实现了高保真度的 4D HOI 生成。    