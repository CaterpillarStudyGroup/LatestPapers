DreamActor-H1: High-Fidelity Human-Product Demonstration Video Generation via Motion-designed Diffusion Transformers


在电子商务和数字营销领域，生成高保真的人-物演示视频对于有效的产品展示至关重要。然而，现有的大多数框架要么无法同时保留人物和产品的身份特征，要么缺乏对人-物空间关系的理解，导致呈现效果不真实、交互动作不自然。   

为应对这些挑战，我们提出了一种基于扩散Transformer（DiT）的框架。我们的方法通过注入配对的人-物参考信息并利用额外的掩码交叉注意力机制，能够同时保留人物身份和产品特有的细节（如标志和纹理）。我们采用三维人体网格模板和产品边界框来提供精确的运动指导，从而实现手势与产品放置位置的直观对齐。此外，我们利用结构化文本编码引入类别级语义信息，增强了在帧间发生微小旋转变化时的三维一致性。   

通过在采用广泛数据增强策略的混合数据集上进行训练，我们的方法在保持人物和产品身份完整性以及生成逼真的演示动作方面，均优于现有前沿技术。   

项目页面：<https://submit2025-dream.github.io/DreamActor-H1/>    
