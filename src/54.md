Person-In-Situ: Scene-Consistent Human Image Insertion with Occlusion-Aware Pose Control

将人体图像合成到场景图像中在娱乐和广告等领域具有广泛的应用前景。然而，现有方法通常无法处理前景物体对插入人物的遮挡问题，且往往将人物简单地放置在最前景层。此外，这些方法对人物姿态的控制能力也较为有限。为解决这些挑战，我们提出了两种创新方法。这两种方法均通过3D人体模型实现显式的姿态控制，并利用潜在扩散模型将人物合成到上下文语境中恰当的深度位置，无需依赖遮挡蒙版即可自然地处理遮挡关系。   

第一种是两阶段方法：模型首先通过监督学习生成包含人物的场景深度图，然后基于该深度图合成人物图像。第二种方法则通过隐式学习遮挡关系，无需显式的深度监督即可直接从输入数据中生成人物图像。定量和定性评估表明，两种方法在准确反映遮挡关系和用户指定姿态的同时，能够更好地保持场景一致性，其综合性能优于现有方法。