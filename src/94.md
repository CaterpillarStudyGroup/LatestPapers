Robust Photo-Realistic Hand Gesture Generation: from Single View to Multiple View

高保真手势生成在以人为本的生成任务中面临重大挑战。现有方法通常采用单视角3D MANO网格渲染图像作为先验来提升手势生成质量。然而，由于手部运动的复杂性和单视角渲染的固有局限性，这种方法难以捕捉完整的三维手部信息，尤其当手指存在遮挡时。其根本矛盾在于：二维投影会导致三维拓扑关系的丢失，而单视角表征又存在空间覆盖不全的缺陷。   

与单视角先验方法不同，我们提出了一种基于多模态UNet特征编码器(MUFEN)的多视角先验框架，通过引导扩散模型学习完整的三维手部信息。具体而言，我们将传统的正视图渲染扩展至包含后视、左视、右视、俯视和仰视的多视角系统，并选择信息量最丰富的视角组合作为训练先验以解决遮挡补全问题。这种配备专用双流编码器的多视角先验机制显著提升了模型对完整手部特征的理解能力。此外，我们设计了边界框特征融合模块，能够将手势定位特征与手势多模态特征相融合，从而增强MUFEN特征对手势相关特征的位置感知能力。实验表明，我们的方法在定量指标和定性评估中均达到了业界领先水平。   