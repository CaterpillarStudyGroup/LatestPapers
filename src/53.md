PrimitiveAnything: Human-Crafted 3D Primitive Assembly Generation with Auto-Regressive Transformer

形状基元抽象通过将复杂三维形状分解为简单几何元素，在人类视觉认知中起着关键作用，并在计算机视觉和图形学领域具有广泛应用。尽管三维内容生成技术近年来取得了显著进展，但现有的基元抽象方法要么依赖有限语义理解的几何优化，要么通过小规模、特定类别的数据集进行学习，难以泛化到多样化的形状类别。我们提出了PrimitiveAnything框架，将形状基元抽象重新定义为基元装配生成任务。该框架包含一个基于形状条件约束的基元Transformer模块用于自回归生成，以及一个无歧义参数化方案来统一表示多种类型的几何基元。通过从大规模人工标注的抽象基元中直接学习装配过程，该框架能够准确捕捉人类分解复杂形状的认知模式。大量实验表明，PrimitiveAnyting生成的基元装配在保持跨类别几何保真度的同时，能够更好地与人类感知对齐。该方法可赋能多种三维应用，并展现出在游戏领域支持基于基元的用户生成内容（UGC）的潜力。项目主页：<https://primitiveanything.github.io>   

