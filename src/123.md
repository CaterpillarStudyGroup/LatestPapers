Absolute Coordinates Make Motion Generation Easy


当前最先进的文本到动作生成模型依赖于由 HumanML3D 推广的运动学感知、局部相对动作表示方法。该方法通过相对于骨盆和前一帧对动作进行编码，并带有内置冗余。虽然这种设计简化了早期生成模型的训练，但它却给扩散模型带来了关键限制，并阻碍了其在下游任务中的应用。   

在这项工作中，我们重新审视了动作表示方法，并为文本到动作生成提出了一种经过彻底简化且被长期弃用的替代方案：全局空间中的**绝对关节坐标**。通过对设计选择的系统分析，我们发现，即使仅使用简单的 Transformer 主干网络且无需辅助的运动学感知损失函数，这种表述方式也能实现**显著更高的动作保真度、改进的文本对齐能力以及强大的可扩展性**。    

此外，我们的方法天然支持下游任务，例如文本驱动的动作控制以及时间/空间编辑，无需额外的任务特定工程改造，也无需根据控制信号进行成本高昂的分类器引导生成。   

最后，我们展示了其良好的泛化能力，能够直接从文本生成运动中的 SMPL-H 网格顶点，为未来的研究和动作相关应用奠定了坚实基础。   