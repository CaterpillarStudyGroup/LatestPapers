PICO: Reconstructing 3D People In Contact with Objects

从单张彩色图像中恢复 3D 人物-物体交互 (HOI) 面临多重挑战，包括深度模糊性、遮挡问题，以及物体形状和外观的巨大多样性。因此，以往研究需要依赖已知物体形状和接触点等受控条件，且仅能处理有限类别的物体。为应对真实场景的需求，我们需要能泛化到自然图像和新型物体类别的方法。本研究通过两大创新实现突破：  

(1) 我们构建了 **PICO-db** 新型数据集，其独特之处在于将自然图像与人体和物体网格上的密集3D接触点进行配对。基于DAMON数据集(已包含标准3D人体接触标注)，我们通过以下方式实现双重接触标注：利用视觉基础模型从数据库检索适配的3D物体网格，并创新性地通过"每接触区域仅需两次点击"的投影方法，将 DAMON 的人体接触区域映射到物体表面。这种极简人工标注方式实现了人体与物体间丰富的接触对应关系。   

(2) 我们提出 **PICO-fit** 渲染比较拟合方法，利用新型接触对应数据集重建交互中的 3D 人体和物体网格。该方法的工作流程包括：推断 SMPL-X 人体的接触信息 → 从 PICO-db 检索匹配的物体网格及接触数据 → 通过优化迭代拟合三维模型使其符合图像证据。PICO-fit 的突破性在于能处理现有方法无法应对的多种物体类别，这对实现真实场景的大规模HOI理解至关重要。   

项目数据与代码已开源：<https://pico.is.tue.mpg.de>