<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Realizing Text-Driven Motion Generation on NAO Robot: A Reinforcement Learning-Optimized Control Pipeline - Latest Paper</title>
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="The note of Latest Articles">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="theme/pagetoc.css">
        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="index.html">Introduction</a></li><li class="chapter-item expanded affix "><li class="part-title">Abstract</li><li class="chapter-item expanded "><a href="*.html"><strong aria-hidden="true">1.</strong> </a></li><li class="chapter-item expanded "><a href="206.html"><strong aria-hidden="true">2.</strong> Physics-based fluid simulation in computer graphics: Survey, research trends, and challenges</a></li><li class="chapter-item expanded "><a href="205.html"><strong aria-hidden="true">3.</strong> Nabla-R2D3: Effective and Efficient 3D Diffusion Alignment with 2D Rewards</a></li><li class="chapter-item expanded "><a href="204.html"><strong aria-hidden="true">4.</strong> Hunyuan3D 2.1: From Images to High-Fidelity 3D Assets with Production-Ready PBR Material</a></li><li class="chapter-item expanded "><a href="202.html"><strong aria-hidden="true">5.</strong> HOIDiNi: Human-Object Interaction through Diffusion Noise Optimization</a></li><li class="chapter-item expanded "><a href="201.html"><strong aria-hidden="true">6.</strong> GenHOI: Generalizing Text-driven 4D Human-Object Interaction Synthesis for Unseen Objects</a></li><li class="chapter-item expanded "><a href="200.html"><strong aria-hidden="true">7.</strong> VideoMAR: Autoregressive Video Generatio with Continuous Tokens</a></li><li class="chapter-item expanded "><a href="199.html"><strong aria-hidden="true">8.</strong> SyncTalk++: High-Fidelity and Efficient Synchronized Talking Heads Synthesis Using Gaussian Splatting</a></li><li class="chapter-item expanded "><a href="198.html"><strong aria-hidden="true">9.</strong> GAF: Gaussian Action Field as a Dvnamic World Model for Robotic Mlanipulation</a></li><li class="chapter-item expanded "><a href="197.html"><strong aria-hidden="true">10.</strong> GMT: General Motion Tracking for Humanoid Whole-Body Control</a></li><li class="chapter-item expanded "><a href="196.html"><strong aria-hidden="true">11.</strong> Toward Rich Video Human-Motion2D Generation</a></li><li class="chapter-item expanded "><a href="195.html"><strong aria-hidden="true">12.</strong> PF-LHM: 3D Animatable Avatar Reconstruction from Pose-free Articulated Human Images</a></li><li class="chapter-item expanded "><a href="194.html"><strong aria-hidden="true">13.</strong> MAMMA: Markerless &amp; Automatic Multi-Person Motion Action Capture</a></li><li class="chapter-item expanded "><a href="193.html"><strong aria-hidden="true">14.</strong> iDiT-HOI: Inpainting-based Hand Object Interaction Reenactment via Video Diffusion Transformer</a></li><li class="chapter-item expanded "><a href="192.html"><strong aria-hidden="true">15.</strong> RL from Physical Feedback: Aligning Large Motion Models with Humanoid Control</a></li><li class="chapter-item expanded "><a href="191.html"><strong aria-hidden="true">16.</strong> KungfuBot: Physics-Based Humanoid Whole-Body Control for Learning Highly-Dynamic Skills</a></li><li class="chapter-item expanded "><a href="190.html"><strong aria-hidden="true">17.</strong> Enter: Graduated Realism: A Pedagogical Framework for AI-Powered Avatars in Virtual Reality Teacher Training</a></li><li class="chapter-item expanded "><a href="189.html"><strong aria-hidden="true">18.</strong> Auto-Connect: Connectivity-Preserving RigFormer with Direct Preference Optimization</a></li><li class="chapter-item expanded "><a href="188.html"><strong aria-hidden="true">19.</strong> SignAligner: Harmonizing Complementary Pose Modalities for Coherent Sign Language Generation</a></li><li class="chapter-item expanded "><a href="187.html"><strong aria-hidden="true">20.</strong> Aligned Novel View Image and Geometry Synthesis via Cross-modal Attention Instillation</a></li><li class="chapter-item expanded "><a href="186.html"><strong aria-hidden="true">21.</strong> AlignHuman: Improving Motion and Fidelity via Timestep-Segment Preference Optimization for Audio-Driven Human Animation</a></li><li class="chapter-item expanded "><a href="185.html"><strong aria-hidden="true">22.</strong> DreamActor-H1: High-Fidelity Human-Product Demonstration Video Generation via Motion-designed Diffusion Transformers</a></li><li class="chapter-item expanded "><a href="184.html"><strong aria-hidden="true">23.</strong> M4V: Multi-Modal Mamba for Text-to-Video Generation</a></li><li class="chapter-item expanded "><a href="183.html"><strong aria-hidden="true">24.</strong> Motion-R1: Chain-of-Thought Reasoning and Reinforcement Learning for Human Motion Generation</a></li><li class="chapter-item expanded "><a href="182.html"><strong aria-hidden="true">25.</strong> Rethinking Generative Human Video Coding with Implicit Motion Transformation</a></li><li class="chapter-item expanded "><a href="181.html"><strong aria-hidden="true">26.</strong> Controllable Expressive 3D Facial Animation via Diffusion in a Unified Multimodal Space</a></li><li class="chapter-item expanded "><a href="180.html"><strong aria-hidden="true">27.</strong> PlayerOne: Egocentric World Simulator</a></li><li class="chapter-item expanded "><a href="178.html"><strong aria-hidden="true">28.</strong> AnimateAnyMesh: A Feed-Forward 4D Foundation Model for Text-Driven Universal Mesh Animation</a></li><li class="chapter-item expanded "><a href="177.html"><strong aria-hidden="true">29.</strong> Self-Supervised Multi-Part Articulated Objects Modeling via Deformable Gaussian Splatting and Progressive Primitive Segmentation</a></li><li class="chapter-item expanded "><a href="176.html"><strong aria-hidden="true">30.</strong> SILK: Smooth InterpoLation frameworK for motion in-betweening A Simplified Computational Approach</a></li><li class="chapter-item expanded "><a href="175.html"><strong aria-hidden="true">31.</strong> RoboSwap: A GAN-driven Video Diffusion Framework For Unsupervised Robot Arm Swapping</a></li><li class="chapter-item expanded "><a href="174.html"><strong aria-hidden="true">32.</strong> StreamSplat: Towards Online Dynamic 3D Reconstruction from Uncalibrated Video Streams</a></li><li class="chapter-item expanded "><a href="173.html"><strong aria-hidden="true">33.</strong> Orientation Matters: Making 3D Generative Models Orientation-Aligned</a></li><li class="chapter-item expanded "><a href="172.html"><strong aria-hidden="true">34.</strong> Generalizable Articulated Object Reconstruction from Casually Captured RGBD Videos</a></li><li class="chapter-item expanded "><a href="171.html"><strong aria-hidden="true">35.</strong> HunyuanVideo-HOMA: Generic Human-Object Interaction in Multimodal Driven Human Animation</a></li><li class="chapter-item expanded "><a href="169.html"><strong aria-hidden="true">36.</strong> Drive Any Mesh: 4D Latent Diffusion for Mesh Deformation from Video</a></li><li class="chapter-item expanded "><a href="168.html"><strong aria-hidden="true">37.</strong> NOVA3D: Normal Aligned Video Diffusion Model for Single Image to 3D Generation</a></li><li class="chapter-item expanded "><a href="167.html"><strong aria-hidden="true">38.</strong> PhysiInter: Integrating Physical Mapping for High-Fidelity Human Interaction Generation</a></li><li class="chapter-item expanded "><a href="166.html"><strong aria-hidden="true">39.</strong> Parametric Gaussian Human Model: Generalizable Prior for Efficient and Realistic Human Avatar Modeling</a></li><li class="chapter-item expanded "><a href="165.html"><strong aria-hidden="true">40.</strong> Revisiting Depth Representations for Feed-Forward 3D Gaussian Splatting </a></li><li class="chapter-item expanded "><a href="164.html"><strong aria-hidden="true">41.</strong> Follow-Your-Creation: Empowering 4D Creation through Video Inpainting</a></li><li class="chapter-item expanded "><a href="163.html" class="active"><strong aria-hidden="true">42.</strong> Realizing Text-Driven Motion Generation on NAO Robot: A Reinforcement Learning-Optimized Control Pipeline</a></li><li class="chapter-item expanded "><a href="162.html"><strong aria-hidden="true">43.</strong> Follow-Your-Motion: Video Motion Transfer via Efficient Spatial-Temporal Decoupled Finetuning</a></li><li class="chapter-item expanded "><a href="160.html"><strong aria-hidden="true">44.</strong> POMP: Physics-consistent Motion Generative Model through Phase Manifolds</a></li><li class="chapter-item expanded "><a href="159.html"><strong aria-hidden="true">45.</strong> SinGS: Animatable Single-Image Human Gaussian Splats with Kinematic Priors</a></li><li class="chapter-item expanded "><a href="158.html"><strong aria-hidden="true">46.</strong> SplArt: Articulation Estimation and Part-Level Reconstruction with 3D Gaussian Splatting</a></li><li class="chapter-item expanded "><a href="157.html"><strong aria-hidden="true">47.</strong> HuGeDiff: 3D Human Generation via Diffusion with Gaussian Splatting</a></li><li class="chapter-item expanded "><a href="156.html"><strong aria-hidden="true">48.</strong> Multimodal Generative AI with Autoregressive LLMs for Human Motion Understanding and Generation: A Way Forward</a></li><li class="chapter-item expanded "><a href="155.html"><strong aria-hidden="true">49.</strong> LinkTo-Anime: A 2D Animation Optical Flow Dataset from 3D Model Rendering</a></li><li class="chapter-item expanded "><a href="153.html"><strong aria-hidden="true">50.</strong> AniMo: Species-Aware Model for Text-Driven Animal Motion Generation</a></li><li class="chapter-item expanded "><a href="152.html"><strong aria-hidden="true">51.</strong> Controllable Human-centric Keyframe Interpolation with Generative Prior</a></li><li class="chapter-item expanded "><a href="151.html"><strong aria-hidden="true">52.</strong> SViMo: Synchronized Diffusion for Video and Motion Generation in Hand-object Interaction Scenarios</a></li><li class="chapter-item expanded "><a href="150.html"><strong aria-hidden="true">53.</strong> HOSIG: Full-Body Human-Object-Scene Interaction Generation with Hierarchical Scene Perception</a></li><li class="chapter-item expanded "><a href="149.html"><strong aria-hidden="true">54.</strong> DiffuseSlide: Training-Free High Frame Rate Video Generation Diffusion </a></li><li class="chapter-item expanded "><a href="148.html"><strong aria-hidden="true">55.</strong> UMA: Ultra-detailed Human Avatars via Multi-level Surface Alignment</a></li><li class="chapter-item expanded "><a href="147.html"><strong aria-hidden="true">56.</strong> FlowMo: Variance-Based Flow Guidance for Coherent Motion in Video Generation</a></li><li class="chapter-item expanded "><a href="146.html"><strong aria-hidden="true">57.</strong> TRiMM: Transformer-Based Rich Motion Matching for Real-Time multi-modal Interaction in Digital Humans</a></li><li class="chapter-item expanded "><a href="145.html"><strong aria-hidden="true">58.</strong> UniGeo: Taming Video Diffusion for Unified Consistent Geometry Estimation</a></li><li class="chapter-item expanded "><a href="144.html"><strong aria-hidden="true">59.</strong> LTM3D: Bridging Token Spaces for Conditional 3D Generation with Auto-Regressive Diffusion Framework</a></li><li class="chapter-item expanded "><a href="143.html"><strong aria-hidden="true">60.</strong> DreamDance: Animating Character Art via Inpainting Stable Gaussian Worlds</a></li><li class="chapter-item expanded "><a href="142.html"><strong aria-hidden="true">61.</strong> AdaHuman: Animatable Detailed 3D Human Generation with Compositional Multiview Diffusion</a></li><li class="chapter-item expanded "><a href="141.html"><strong aria-hidden="true">62.</strong> Generating Fit Check Videos with a Handheld Camera</a></li><li class="chapter-item expanded "><a href="140.html"><strong aria-hidden="true">63.</strong> GeoMan: Temporally Consistent Human Geometry Estimation using Image-to-Video Diffusion</a></li><li class="chapter-item expanded "><a href="139.html"><strong aria-hidden="true">64.</strong> MMGT: Motion Mask Guided Two-Stage Network for Co-Speech Gesture Video Generation</a></li><li class="chapter-item expanded "><a href="138.html"><strong aria-hidden="true">65.</strong> ATI: Any Trajectory Instruction for Controllable Video Generation</a></li><li class="chapter-item expanded "><a href="137.html"><strong aria-hidden="true">66.</strong> Hallo4: High-Fidelity Dynamic Portrait Animation via Direct Preference Optimization and Temporal Motion Modulation</a></li><li class="chapter-item expanded "><a href="136.html"><strong aria-hidden="true">67.</strong> HyperMotion: DiT-Based Pose-Guided Human Image Animation of Complex Motions</a></li><li class="chapter-item expanded "><a href="135.html"><strong aria-hidden="true">68.</strong> LatentMove: Towards Complex Human Movement Video Generation </a></li><li class="chapter-item expanded "><a href="133.html"><strong aria-hidden="true">69.</strong> Diffusion Model-based Activity Completion for AI Motion Capture from Videos</a></li><li class="chapter-item expanded "><a href="131.html"><strong aria-hidden="true">70.</strong> How Much Do Large Language Models Know about Human Motion? A Case Study in 3D Avatar Control</a></li><li class="chapter-item expanded "><a href="129.html"><strong aria-hidden="true">71.</strong> AniCrafter: Customizing Realistic Human-Centric Animation via Avatar-Background Conditioning in Video Diffusion Models</a></li><li class="chapter-item expanded "><a href="127.html"><strong aria-hidden="true">72.</strong> MotionPro: A Precise Motion Controller for Image-to-Video Generation</a></li><li class="chapter-item expanded "><a href="126.html"><strong aria-hidden="true">73.</strong> DIPO: Dual-State Images Controlled Articulated Object Generation Powered by Diverse Data</a></li><li class="chapter-item expanded "><a href="125.html"><strong aria-hidden="true">74.</strong> Force Prompting: Video Generation Models Can Learn and Generalize Physics-based Control Signals</a></li><li class="chapter-item expanded "><a href="122.html"><strong aria-hidden="true">75.</strong> Flow Matching for Geometric Trajectory Simulation</a></li><li class="chapter-item expanded "><a href="121.html"><strong aria-hidden="true">76.</strong> Pose Splatter: A 3D Gaussian Splatting Model for Quantifying Animal Pose and Appearance</a></li><li class="chapter-item expanded "><a href="120.html"><strong aria-hidden="true">77.</strong> CGS-GAN: 3D Consistent Gaussian Splatting GANs for High Resolution Human Head Synthesis</a></li><li class="chapter-item expanded "><a href="119.html"><strong aria-hidden="true">78.</strong> Multi-Person Interaction Generation from Two-Person Motion Priors</a></li><li class="chapter-item expanded "><a href="118.html"><strong aria-hidden="true">79.</strong> DanceTogether! Identity-Preserving Multi-Person Interactive Video Generation</a></li><li class="chapter-item expanded "><a href="117.html"><strong aria-hidden="true">80.</strong> Temporal Differential Fields for 4D Motion Modeling via Image-to-Video Synthesis</a></li><li class="chapter-item expanded "><a href="116.html"><strong aria-hidden="true">81.</strong> WonderPlay: Dynamic 3D Scene Generation from a Single Image and Actions</a></li><li class="chapter-item expanded "><a href="115.html"><strong aria-hidden="true">82.</strong> Motion Matters: Compact Gaussian Streaming for Free-Viewpoint Video Reconstruction</a></li><li class="chapter-item expanded "><a href="114.html"><strong aria-hidden="true">83.</strong> Pursuing Temporal-Consistent Video Virtual Try-On via Dynamic Pose Interaction</a></li><li class="chapter-item expanded "><a href="113.html"><strong aria-hidden="true">84.</strong> SHaDe: Compact and Consistent Dynamic 3D Reconstruction via Tri-Plane Deformation and Latent Diffusion</a></li><li class="chapter-item expanded "><a href="112.html"><strong aria-hidden="true">85.</strong> MEgoHand: Multimodal Egocentric Hand-Object Interaction Motion Generation</a></li><li class="chapter-item expanded "><a href="111.html"><strong aria-hidden="true">86.</strong> MAGIC: Motion-Aware Generative Inference via Confidence-Guided LLM</a></li><li class="chapter-item expanded "><a href="108.html"><strong aria-hidden="true">87.</strong> GS2E: Gaussian Splatting is an Effective Data Generator for Event Stream Generation</a></li><li class="chapter-item expanded "><a href="107.html"><strong aria-hidden="true">88.</strong> EVA: Expressive Virtual Avatars from Multi-view Videos</a></li><li class="chapter-item expanded "><a href="105.html"><strong aria-hidden="true">89.</strong> Large-Scale Multi-Character Interaction Synthesis</a></li><li class="chapter-item expanded "><a href="104.html"><strong aria-hidden="true">90.</strong> Hunyuan-Game: Industrial-grade Intelligent Game Creation Model</a></li><li class="chapter-item expanded "><a href="103.html"><strong aria-hidden="true">91.</strong> Vid2World: Crafting Video Diffusion Models to Interactive World Models</a></li><li class="chapter-item expanded "><a href="102.html"><strong aria-hidden="true">92.</strong> MGStream: Motion-aware 3D Gaussian for Streamable Dynamic Scene Reconstruction</a></li><li class="chapter-item expanded "><a href="101.html"><strong aria-hidden="true">93.</strong> LMP: Leveraging Motion Prior in Zero-Shot Video Generation with Diffusion Transformer</a></li><li class="chapter-item expanded "><a href="100.html"><strong aria-hidden="true">94.</strong> Video-GPT via Next Clip Diffusion</a></li><li class="chapter-item expanded "><a href="99.html"><strong aria-hidden="true">95.</strong> MonoMobility: Zero-Shot 3D Mobility Analysis from Monocular Videos</a></li><li class="chapter-item expanded "><a href="98.html"><strong aria-hidden="true">96.</strong> RoPECraft: Training-Free Motion Transfer with Trajectory-Guided RoPE Optimization on Diffusion Transformers</a></li><li class="chapter-item expanded "><a href="97.html"><strong aria-hidden="true">97.</strong> UniHM: Universal Human Motion Generation with Object Interactions in Indoor Scenes</a></li><li class="chapter-item expanded "><a href="95.html"><strong aria-hidden="true">98.</strong> PoseBench3D: A Cross-Dataset Analysis Framework for 3D Human Pose Estimation</a></li><li class="chapter-item expanded "><a href="94.html"><strong aria-hidden="true">99.</strong> Robust Photo-Realistic Hand Gesture Generation: from Single View to Multiple View</a></li><li class="chapter-item expanded "><a href="93.html"><strong aria-hidden="true">100.</strong> Infinigen-Sim: Procedural Generation of Articulated Simulation Assets</a></li><li class="chapter-item expanded "><a href="90.html"><strong aria-hidden="true">101.</strong> Locality Sensitive Avatars From Video</a></li><li class="chapter-item expanded "><a href="89.html"><strong aria-hidden="true">102.</strong> Dyadic Mamba: Long-term Dyadic Human Motion Synthesis</a></li><li class="chapter-item expanded "><a href="86.html"><strong aria-hidden="true">103.</strong> MTVCrafter: 4D Motion Tokenization for Open-World Human Image Animation</a></li><li class="chapter-item expanded "><a href="85.html"><strong aria-hidden="true">104.</strong> TexTailor: Customized Text-aligned Texturing via Effective Resampling</a></li><li class="chapter-item expanded "><a href="82.html"><strong aria-hidden="true">105.</strong> CameraCtrl: Enabling Camera Control for Video Diffusion Models</a></li><li class="chapter-item expanded "><a href="81.html"><strong aria-hidden="true">106.</strong> ACT-R: Adaptive Camera Trajectories for 3D Reconstruction from Single Image</a></li><li class="chapter-item expanded "><a href="80.html"><strong aria-hidden="true">107.</strong> M3G: Multi-Granular Gesture Generator for Audio-Driven Full-Body Human Motion Synthesis</a></li><li class="chapter-item expanded "><a href="78.html"><strong aria-hidden="true">108.</strong> CyberHost: A One-stage Diffusion Framework for Audio-driven Talking Body Generation</a></li><li class="chapter-item expanded "><a href="76.html"><strong aria-hidden="true">109.</strong> Sketch2Anim: Towards Transferring Sketch Storyboards into 3D Animation</a></li><li class="chapter-item expanded "><a href="75.html"><strong aria-hidden="true">110.</strong> Step1X-3D: Towards High-Fidelity and Controllable Generation of Textured 3D Assets</a></li><li class="chapter-item expanded "><a href="74.html"><strong aria-hidden="true">111.</strong> Link to the Past: Temporal Propagation for Fast 3D Human Reconstruction from Monocular Video</a></li><li class="chapter-item expanded "><a href="73.html"><strong aria-hidden="true">112.</strong> ShotAdapter: Text-to-Multi-Shot Video Generation with Diffusion Models</a></li><li class="chapter-item expanded "><a href="72.html"><strong aria-hidden="true">113.</strong> Human Motion Prediction via Test-domain-aware Adaptation with Easily-available Human Motions Estimated from Videos</a></li><li class="chapter-item expanded "><a href="71.html"><strong aria-hidden="true">114.</strong> MAGE:A Multi-stage Avatar Generator with Sparse Observations</a></li><li class="chapter-item expanded "><a href="70.html"><strong aria-hidden="true">115.</strong> DiffLocks: Generating 3D Hair from a Single Image using Diffusion Models</a></li><li class="chapter-item expanded "><a href="69.html"><strong aria-hidden="true">116.</strong> TeGA: Texture Space Gaussian Avatars for High-Resolution Dynamic Head Modeling</a></li><li class="chapter-item expanded "><a href="68.html"><strong aria-hidden="true">117.</strong> Anymate: A Dataset and Baselines for Learning 3D Object Rigging</a></li><li class="chapter-item expanded "><a href="67.html"><strong aria-hidden="true">118.</strong> ReactDance: Progressive-Granular Representation for Long-Term Coherent Reactive Dance Generation</a></li><li class="chapter-item expanded "><a href="66.html"><strong aria-hidden="true">119.</strong> Apply Hierarchical-Chain-of-Generation to Complex Attributes Text-to-3D Generation</a></li><li class="chapter-item expanded "><a href="65.html"><strong aria-hidden="true">120.</strong> Humanise: Language-conditioned human motion generation in 3d scenes</a></li><li class="chapter-item expanded "><a href="64.html"><strong aria-hidden="true">121.</strong> Synthesizing Diverse Human Motions in 3D Indoor Scenes</a></li><li class="chapter-item expanded "><a href="63.html"><strong aria-hidden="true">122.</strong> Move as You Say, Interact as You Can:Language-guided Human Motion Generation with Scene Affordance</a></li><li class="chapter-item expanded "><a href="62.html"><strong aria-hidden="true">123.</strong> 3D Scene Generation: A Survey</a></li><li class="chapter-item expanded "><a href="61.html"><strong aria-hidden="true">124.</strong> SVAD: From Single Image to 3D Avatar via Synthetic Data Generation with Video Diffusion and Data Augmentation</a></li><li class="chapter-item expanded "><a href="58.html"><strong aria-hidden="true">125.</strong> MeshGen: Generating PBR Textured Mesh with Render-Enhanced Auto-Encoder and Generative Data Augmentation</a></li><li class="chapter-item expanded "><a href="57.html"><strong aria-hidden="true">126.</strong> TokenHSI: Unified Synthesis of Physical Human-Scene Interactions through Task Tokenization</a></li><li class="chapter-item expanded "><a href="56.html"><strong aria-hidden="true">127.</strong> ELGAR: Expressive Cello Performance Motion Generation for Audio Rendition</a></li><li class="chapter-item expanded "><a href="55.html"><strong aria-hidden="true">128.</strong> PARC: Physics-based Augmentation with Reinforcement Learning for Character Controllers</a></li><li class="chapter-item expanded "><a href="54.html"><strong aria-hidden="true">129.</strong> Person-In-Situ: Scene-Consistent Human Image Insertion with Occlusion-Aware Pose Control</a></li><li class="chapter-item expanded "><a href="53.html"><strong aria-hidden="true">130.</strong> PrimitiveAnything: Human-Crafted 3D Primitive Assembly Generation with Auto-Regressive Transformer</a></li><li class="chapter-item expanded "><a href="52.html"><strong aria-hidden="true">131.</strong> Bridging Geometry-Coherent Text-to-3D Generation with Multi-View Diffusion Priors and Gaussian Splatting</a></li><li class="chapter-item expanded "><a href="51.html"><strong aria-hidden="true">132.</strong> FlexiAct: Towards Flexible Action Control in Heterogeneous Scenarios</a></li><li class="chapter-item expanded "><a href="50.html"><strong aria-hidden="true">133.</strong> Real-Time Person Image Synthesis Using a Flow Matching Model</a></li><li class="chapter-item expanded "><a href="49.html"><strong aria-hidden="true">134.</strong> Polar Coordinate-Based 2D Pose Prior with Neural Distance Field</a></li><li class="chapter-item expanded "><a href="48.html"><strong aria-hidden="true">135.</strong> PAHA: Parts-Aware Audio-Driven Human Animation with Diffusion Model</a></li><li class="chapter-item expanded "><a href="47.html"><strong aria-hidden="true">136.</strong> GUAVA: Generalizable Upper Body 3D Gaussian Avatar</a></li><li class="chapter-item expanded "><a href="46.html"><strong aria-hidden="true">137.</strong> DualReal: Adaptive Joint Training for Lossless Identity-Motion Fusion in Video Customization</a></li><li class="chapter-item expanded "><a href="45.html"><strong aria-hidden="true">138.</strong> SignSplat: Rendering Sign Language via Gaussian Splatting</a></li><li class="chapter-item expanded "><a href="44.html"><strong aria-hidden="true">139.</strong> MVHumanNet++: A Large-scale Dataset of Multi-view Daily Dressing Human Captures with Richer Annotations for 3D Human Digitization </a></li><li class="chapter-item expanded "><a href="43.html"><strong aria-hidden="true">140.</strong> Co$^{3}$Gesture: Towards Coherent Concurrent Co-speech 3D Gesture Generation with Interactive Diffusion</a></li><li class="chapter-item expanded "><a href="42.html"><strong aria-hidden="true">141.</strong> Efficient 3D Full-Body Motion Generation from Sparse Tracking Inputs with Temporal Windows</a></li><li class="chapter-item expanded "><a href="41.html"><strong aria-hidden="true">142.</strong> Model See Model Do: Speech-Driven Facial Animation with Style Control</a></li><li class="chapter-item expanded "><a href="40.html"><strong aria-hidden="true">143.</strong> 3D Human Pose Estimation via Spatial Graph Order Attention and Temporal Body Aware Transformer</a></li><li class="chapter-item expanded "><a href="36.html"><strong aria-hidden="true">144.</strong> JointDiT: Enhancing RGB-Depth Joint Modeling with Diffusion Transformers</a></li><li class="chapter-item expanded "><a href="35.html"><strong aria-hidden="true">145.</strong> Eye2Eye: A Simple Approach for Monocular-to-Stereo Video Synthesis</a></li><li class="chapter-item expanded "><a href="34.html"><strong aria-hidden="true">146.</strong> T2VPhysBench: A First-Principles Benchmark for Physical Consistency in Text-to-Video Generation</a></li><li class="chapter-item expanded "><a href="33.html"><strong aria-hidden="true">147.</strong> Direct Motion Models for Assessing Generated Videos</a></li><li class="chapter-item expanded "><a href="32.html"><strong aria-hidden="true">148.</strong> Real-Time Animatable 2DGS-Avatars with Detail Enhancement from Monocular Videos</a></li><li class="chapter-item expanded "><a href="31.html"><strong aria-hidden="true">149.</strong> CoCoDiff: Diversifying Skeleton Action Features via Coarse-Fine Text-Co-Guided Latent Diffusion</a></li><li class="chapter-item expanded "><a href="30.html"><strong aria-hidden="true">150.</strong> Common3D: Self-Supervised Learning of 3D Morphable Models for Common Objects in Neural Feature Space</a></li><li class="chapter-item expanded "><a href="29.html"><strong aria-hidden="true">151.</strong> HoloTime: Taming Video Diffusion Models for Panoramic 4D Scene Generation</a></li><li class="chapter-item expanded "><a href="28.html"><strong aria-hidden="true">152.</strong> MagicPortrait: Temporally Consistent Face Reenactment with 3D Geometric Guidance</a></li><li class="chapter-item expanded "><a href="27.html"><strong aria-hidden="true">153.</strong> ReVision: High-Quality, Low-Cost Video Generation with Explicit 3D Physics Modeling for Complex Motion and Interaction</a></li><li class="chapter-item expanded "><a href="25.html"><strong aria-hidden="true">154.</strong> Efficient Listener: Dyadic Facial Motion Synthesis via Action Diffusion</a></li><li class="chapter-item expanded "><a href="24.html"><strong aria-hidden="true">155.</strong> Creating Your Editable 3D Photorealistic Avatar with Tetrahedron-constrained Gaussian Splatting</a></li><li class="chapter-item expanded "><a href="23.html"><strong aria-hidden="true">156.</strong> SoccerDiffusion: Toward Learning End-to-End Humanoid Robot Soccer from Gameplay Recordings</a></li><li class="chapter-item expanded "><a href="22.html"><strong aria-hidden="true">157.</strong> TesserAct: Learning 4D Embodied World Models</a></li><li class="chapter-item expanded "><a href="21.html"><strong aria-hidden="true">158.</strong> EfficientHuman: Efficient Training and Reconstruction of Moving Human using Articulated 2D Gaussian</a></li><li class="chapter-item expanded "><a href="20.html"><strong aria-hidden="true">159.</strong> Joint Optimization of Neural Radiance Fields and Continuous Camera Motion from a Monocular Video</a></li><li class="chapter-item expanded "><a href="19.html"><strong aria-hidden="true">160.</strong> Sketch2Anim: Towards Transferring Sketch Storyboards into 3D Animation</a></li><li class="chapter-item expanded "><a href="18.html"><strong aria-hidden="true">161.</strong> HumMorph: Generalized Dynamic Human Neural Fields from Few Views</a></li><li class="chapter-item expanded "><a href="17.html"><strong aria-hidden="true">162.</strong> AnimateAnywhere: Rouse the Background in Human Image Animation</a></li><li class="chapter-item expanded "><a href="16.html"><strong aria-hidden="true">163.</strong> Generative AI for Character Animation: A Comprehensive Survey of Techniques, Applications, and Future Directions</a></li><li class="chapter-item expanded "><a href="15.html"><strong aria-hidden="true">164.</strong> ActionArt: Advancing Multimodal Large Models for Fine-Grained Human-Centric Video Understanding</a></li><li class="chapter-item expanded "><a href="14.html"><strong aria-hidden="true">165.</strong> SmallGS: Gaussian Splatting-based Camera Pose Estimation for Small-Baseline Videos</a></li><li class="chapter-item expanded "><a href="13.html"><strong aria-hidden="true">166.</strong> STP4D: Spatio-Temporal-Prompt Consistent Modeling for Text-to-4D Gaussian Splatting</a></li><li class="chapter-item expanded "><a href="12.html"><strong aria-hidden="true">167.</strong> Unify3D: An Augmented Holistic End-to-end Monocular 3D Human Reconstruction via Anatomy Shaping and Twins Negotiating</a></li><li class="chapter-item expanded "><a href="11.html"><strong aria-hidden="true">168.</strong> SSD-Poser: Avatar Pose Estimation with State Space Duality from Sparse Observations</a></li><li class="chapter-item expanded "><a href="10.html"><strong aria-hidden="true">169.</strong> PIN-WM: Learning Physics-INformed World Models for Non-Prehensile Manipulation</a></li><li class="chapter-item expanded "><a href="9.html"><strong aria-hidden="true">170.</strong> Gaussian Splatting is an Effective Data Generator for 3D Object Detection</a></li><li class="chapter-item expanded "><a href="8.html"><strong aria-hidden="true">171.</strong> HUG: Hierarchical Urban Gaussian Splatting with Block-Based Reconstruction</a></li><li class="chapter-item expanded "><a href="7.html"><strong aria-hidden="true">172.</strong> Physically Consistent Humanoid Loco-Manipulation using Latent Diffusion Models</a></li><li class="chapter-item expanded "><a href="5.html"><strong aria-hidden="true">173.</strong> Unveiling Hidden Vulnerabilities in Digital Human Generation via Adversarial Attacks</a></li><li class="chapter-item expanded "><a href="4.html"><strong aria-hidden="true">174.</strong> PICO: Reconstructing 3D People In Contact with Objects</a></li><li class="chapter-item expanded "><a href="3.html"><strong aria-hidden="true">175.</strong> Bolt: Clothing Virtual Characters at Scale</a></li><li class="chapter-item expanded "><a href="2.html"><strong aria-hidden="true">176.</strong> Dynamic Camera Poses and Where to Find Them</a></li><li class="chapter-item expanded "><a href="1.html"><strong aria-hidden="true">177.</strong> 3DV-TON: Textured 3D-Guided Consistent Video Try-on via Diffusion Models</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Latest Paper</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/CaterpillarStudyGroup/LatestPapers" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main><div class="sidetoc"><nav class="pagetoc"></nav></div>
                        <p>Realizing Text-Driven Motion Generation on NAO Robot: A Reinforcement Learning-Optimized Control Pipeline</p>
<p>人形机器人运动重定向技术旨在将人类运动数据转化为机器人动作以实现模仿，虽存在显著挑战但在实际应用中具有巨大潜力。传统方法依赖于通过姿态估计或动作捕捉系统采集的人类示范数据。本文提出一种文本驱动的人形机器人运动映射方法。为克服生成运动表征与人形机器人运动学约束之间的固有差异，我们设计了基于位置范数与旋转损失函数(NPR Loss)的角度信号网络。该网络生成的关节角度将作为输入，驱动基于强化学习的全身关节运动控制策略。该策略在追踪生成运动的同时，确保机器人在执行过程中保持稳定性。实验结果表明，本方法成功实现了文本驱动的人类运动向真实人形机器人NAO的迁移。    </p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="164.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>
                            <a rel="next" href="162.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="164.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>
                    <a rel="next" href="162.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript" src="theme/pagetoc.js"></script>
    </body>
</html>
